{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 1 Redes Neuronales Artificiales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andrea Figueroa, \n",
    "Alejandro Sazo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Generación de data aleatoria que represente la función lógica $xor$. Se generan 1000 datos de prueba y 1000 de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importar Librerías\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAGnCAYAAADbg3JOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDMMUBQsbwzAMUxT/H0m3Tet2fFa0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f63b4c349d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Guardar semilla para numeros aleatorios\n",
    "seed = 20\n",
    "np.random.seed(seed)\n",
    "\n",
    "def generate_data(n):\n",
    "    \n",
    "    # Lista para guardar datos etiquetados\n",
    "    output = list()\n",
    "    \n",
    "    # Generación de n tuplas aleatorias\n",
    "    input = 2 * np.random.random_sample((n,2)) - 1\n",
    "    # Asignación datos dependiendo del cuadrante\n",
    "    for i in input:\n",
    "        # Cuadrante 1\n",
    "        if i[0] > 0 and i[1] > 0:\n",
    "            output.append(0)\n",
    "        # Cuadrante 2\n",
    "        elif i[0] < 0 and i[1] > 0: \n",
    "            output.append(1)\n",
    "        # Cuadrante 3\n",
    "        elif i[0] < 0 and i[1] < 0: \n",
    "            output.append(0)\n",
    "        # Cuadrante 4\n",
    "        elif i[0] > 0 and i[1] < 0: \n",
    "            output.append(1)\n",
    "    return input, output\n",
    "\n",
    "(x_training, y_training) = generate_data(1000)\n",
    "(x_test, y_test) = generate_data(1000)\n",
    "\n",
    "# Plot de datos de entrenamiento\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(7,7))\n",
    "set1 = x_training[np.logical_and(x_training[:,0] < 0, x_training[:,1] < 0)]\n",
    "set2 = x_training[np.logical_and(x_training[:,0] < 0, x_training[:,1] > 0)]\n",
    "set3 = x_training[np.logical_and(x_training[:,0] > 0, x_training[:,1] > 0)]\n",
    "set4 = x_training[np.logical_and(x_training[:,0] > 0, x_training[:,1] < 0)]\n",
    "set1 = np.concatenate((set1, set3), axis=0)\n",
    "set2 = np.concatenate((set2, set4), axis=0)\n",
    "plt.plot(set1[:,0], set1[:,1], 'r.')\n",
    "plt.plot(set2[:,0], set2[:,1], 'bx')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Generación de una neurona. Ha sido entrenada con 1000 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neurona inicializada\n",
      "Neurona entrenada\n",
      "1000/1000 [==============================] - 0s\n",
      "0.250243514776\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "# Creación de una neurona\n",
    "model = Sequential()\n",
    "\n",
    "# Dimensión input = 1, Dimensión output = 2, función de activación es Relu\n",
    "model.add(Dense(output_dim=1, input_dim=2, init=\"normal\"))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "print \"Neurona inicializada\"\n",
    "\n",
    "# Entrenar a la neurona\n",
    "model.fit(x_training, y_training, nb_epoch=1000,verbose=0)\n",
    "\n",
    "print \"Neurona entrenada\"\n",
    "\n",
    "# Evaluar la neurona\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=1000)\n",
    "print loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4691\n",
      "0.5263\n",
      "0.4879\n",
      "0.5075\n"
     ]
    }
   ],
   "source": [
    "print round(model.predict(np.array([-1,-1]).reshape(1,2))[0][0],4)\n",
    "print round(model.predict(np.array([1,1]).reshape(1,2))[0][0],4)\n",
    "print round(model.predict(np.array([-1,1]).reshape(1,2))[0][0],4)\n",
    "print round(model.predict(np.array([1,-1]).reshape(1,2))[0][0],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neurona inicializada\n",
      "Neurona entrenada\n",
      "1000/1000 [==============================] - 0s\n",
      "0.0075051295571\n"
     ]
    }
   ],
   "source": [
    "# Ejercicio 1.3\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "# Creación de una neurona\n",
    "xor = Sequential()\n",
    "\n",
    "# Dimensión input = 1, Dimensión output = 2, función de activación es Relu\n",
    "xor.add(Dense(8, input_dim = 2, activation = \"relu\"))\n",
    "xor.add(Dense(1, activation = \"sigmoid\"))\n",
    "xor.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "print \"Neurona inicializada\"\n",
    "\n",
    "# Entrenar a la neurona\n",
    "xor.fit(x_training, y_training, nb_epoch=1000, verbose=0)\n",
    "\n",
    "print \"Neurona entrenada\"\n",
    "\n",
    "# Evaluar la neurona\n",
    "evaluacion = xor.evaluate(x_test, y_test, batch_size=1000)\n",
    "print evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print round(xor.predict(np.array([-1,-1]).reshape(1,2))[0][0],4)\n",
    "print round(xor.predict(np.array([1,1]).reshape(1,2))[0][0],4)\n",
    "print round(xor.predict(np.array([-1,1]).reshape(1,2))[0][0],4)\n",
    "print round(xor.predict(np.array([1,-1]).reshape(1,2))[0][0],4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Construcción del dataframe para el set Boston Housing. Este set se divide para generar el training set y el testing set. Del total de datos, el 25% se deja aparte para pruebas y el restante 75% permanece para entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'http://mldata.org/repository/data/download/csv/regression-datasets-housing/'\n",
    "df = pd.read_csv(url, sep=',',header=None, names=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX',\n",
    "'RM', 'AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV'])\n",
    "from sklearn.cross_validation import train_test_split\n",
    "df_train, df_test = train_test_split(df,test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Descripción del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      "CRIM       506 non-null float64\n",
      "ZN         506 non-null int64\n",
      "INDUS      506 non-null float64\n",
      "CHAS       506 non-null int64\n",
      "NOX        506 non-null float64\n",
      "RM         506 non-null float64\n",
      "AGE        506 non-null float64\n",
      "DIS        506 non-null float64\n",
      "RAD        506 non-null int64\n",
      "TAX        506 non-null int64\n",
      "PTRATIO    506 non-null int64\n",
      "B          506 non-null float64\n",
      "LSTAT      506 non-null float64\n",
      "MEDV       506 non-null float64\n",
      "dtypes: float64(9), int64(5)\n",
      "memory usage: 59.3 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.347826</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.083004</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.310593</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.280574</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677082</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.347826   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.310593    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677082   12.000000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.083004  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.280574   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.000000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.000000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.000000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.000000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT        MEDV  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Normalización de datos. Este procedimiento es necesario para (completalo andrea)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(df_train)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(df_train),columns=df_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(df_test),columns=df_test.columns)\n",
    "y_train_scaled = X_train_scaled.pop('MEDV')\n",
    "y_test_scaled = X_test_scaled.pop('MEDV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Gráfico de MSE versus número de epochs utilizados para entrenar para red FF de 3 capas, 200 unidades ocultas y activación sigmoidal entrenada con SGD con parámetros $\\eta$=0.2 y 300 epochs de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAGJCAYAAABhFP8OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f63aa45b2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(200, input_dim=X_train_scaled.shape[1], init='uniform'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1, init='uniform'))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "sgd = SGD(lr=0.2)\n",
    "model.compile(optimizer='sgd',loss='mean_squared_error')\n",
    "\n",
    "hist = model.fit(X_train_scaled.as_matrix(), y_train_scaled.as_matrix(), \n",
    "                 nb_epoch=300, verbose=0, \n",
    "                 validation_data=(X_test_scaled.as_matrix(), y_test_scaled.as_matrix()))\n",
    "\n",
    "%matplotlib inline\n",
    "epochs = np.arange(300)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(epochs, hist.history['loss'], 'b-')\n",
    "plt.title(u\"Función de activación sigmoidal\")\n",
    "plt.xlabel(\"# epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Variar función de activación cambiandola por ReLu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEZCAYAAAB8culNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMwbujWqcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f63b4aabb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(200, input_dim=X_train_scaled.shape[1], init='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dense(1, init='uniform'))\n",
    "model2.add(Activation('linear'))\n",
    "\n",
    "sgd = SGD(lr=0.2)\n",
    "model2.compile(optimizer='sgd',loss='mean_squared_error')\n",
    "\n",
    "hist2 = model2.fit(X_train_scaled.as_matrix(), y_train_scaled.as_matrix(), \n",
    "                   nb_epoch=300, verbose=0, \n",
    "                   validation_data=(X_test_scaled.as_matrix(), y_test_scaled.as_matrix()))\n",
    "\n",
    "%matplotlib inline\n",
    "epochs = np.arange(300)\n",
    "plt.plot(epochs, hist2.history['loss'], 'r-')\n",
    "plt.title(u\"Función de activación ReLu\")\n",
    "plt.xlabel(\"# epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Variar learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_lr = 20\n",
    "lear_rate = np.linspace(0,1,n_lr)\n",
    "# La andrea lo va a hacer Firma:andrea 11:41\n",
    "# Modularizar modelo de d) para poder cambiar la función de activación y learning rate\n",
    "# Plotear fuera del for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "341/341 [==============================] - 0s - loss: 0.9639     \n",
      "Epoch 2/300\n",
      "341/341 [==============================] - 0s - loss: 0.8661     \n",
      "Epoch 3/300\n",
      "341/341 [==============================] - 0s - loss: 0.7756     \n",
      "Epoch 4/300\n",
      "341/341 [==============================] - 0s - loss: 0.6866     \n",
      "Epoch 5/300\n",
      "341/341 [==============================] - 0s - loss: 0.6029     \n",
      "Epoch 6/300\n",
      "341/341 [==============================] - 0s - loss: 0.5270     \n",
      "Epoch 7/300\n",
      "341/341 [==============================] - 0s - loss: 0.4636     \n",
      "Epoch 8/300\n",
      "341/341 [==============================] - 0s - loss: 0.4108     \n",
      "Epoch 9/300\n",
      "341/341 [==============================] - 0s - loss: 0.3683     \n",
      "Epoch 10/300\n",
      "341/341 [==============================] - 0s - loss: 0.3325     \n",
      "Epoch 11/300\n",
      "341/341 [==============================] - 0s - loss: 0.3057     \n",
      "Epoch 12/300\n",
      "341/341 [==============================] - 0s - loss: 0.2817     \n",
      "Epoch 13/300\n",
      "341/341 [==============================] - 0s - loss: 0.2624     \n",
      "Epoch 14/300\n",
      "341/341 [==============================] - 0s - loss: 0.2473     \n",
      "Epoch 15/300\n",
      "341/341 [==============================] - 0s - loss: 0.2338     \n",
      "Epoch 16/300\n",
      "341/341 [==============================] - 0s - loss: 0.2231     \n",
      "Epoch 17/300\n",
      "341/341 [==============================] - 0s - loss: 0.2153     \n",
      "Epoch 18/300\n",
      "341/341 [==============================] - 0s - loss: 0.2083     \n",
      "Epoch 19/300\n",
      "341/341 [==============================] - 0s - loss: 0.2024     \n",
      "Epoch 20/300\n",
      "341/341 [==============================] - 0s - loss: 0.1977     \n",
      "Epoch 21/300\n",
      "341/341 [==============================] - 0s - loss: 0.1934     \n",
      "Epoch 22/300\n",
      "341/341 [==============================] - 0s - loss: 0.1904     \n",
      "Epoch 23/300\n",
      "341/341 [==============================] - 0s - loss: 0.1875     \n",
      "Epoch 24/300\n",
      "341/341 [==============================] - 0s - loss: 0.1840     \n",
      "Epoch 25/300\n",
      "341/341 [==============================] - 0s - loss: 0.1817     \n",
      "Epoch 26/300\n",
      "341/341 [==============================] - 0s - loss: 0.1792     \n",
      "Epoch 27/300\n",
      "341/341 [==============================] - 0s - loss: 0.1768     \n",
      "Epoch 28/300\n",
      "341/341 [==============================] - 0s - loss: 0.1748     \n",
      "Epoch 29/300\n",
      "341/341 [==============================] - 0s - loss: 0.1727     \n",
      "Epoch 30/300\n",
      "341/341 [==============================] - 0s - loss: 0.1709     \n",
      "Epoch 31/300\n",
      "341/341 [==============================] - 0s - loss: 0.1691     \n",
      "Epoch 32/300\n",
      "341/341 [==============================] - 0s - loss: 0.1677     \n",
      "Epoch 33/300\n",
      "341/341 [==============================] - 0s - loss: 0.1666     \n",
      "Epoch 34/300\n",
      "341/341 [==============================] - 0s - loss: 0.1642     \n",
      "Epoch 35/300\n",
      "341/341 [==============================] - 0s - loss: 0.1630     \n",
      "Epoch 36/300\n",
      "341/341 [==============================] - 0s - loss: 0.1623     \n",
      "Epoch 37/300\n",
      "341/341 [==============================] - 0s - loss: 0.1605     \n",
      "Epoch 38/300\n",
      "341/341 [==============================] - 0s - loss: 0.1591     \n",
      "Epoch 39/300\n",
      "341/341 [==============================] - 0s - loss: 0.1583     \n",
      "Epoch 40/300\n",
      "341/341 [==============================] - 0s - loss: 0.1566     \n",
      "Epoch 41/300\n",
      "341/341 [==============================] - 0s - loss: 0.1555     \n",
      "Epoch 42/300\n",
      "341/341 [==============================] - 0s - loss: 0.1544     \n",
      "Epoch 43/300\n",
      "341/341 [==============================] - 0s - loss: 0.1532     \n",
      "Epoch 44/300\n",
      "341/341 [==============================] - 0s - loss: 0.1520     \n",
      "Epoch 45/300\n",
      "341/341 [==============================] - 0s - loss: 0.1510     \n",
      "Epoch 46/300\n",
      "341/341 [==============================] - 0s - loss: 0.1504     \n",
      "Epoch 47/300\n",
      "341/341 [==============================] - 0s - loss: 0.1490     \n",
      "Epoch 48/300\n",
      "341/341 [==============================] - 0s - loss: 0.1483     \n",
      "Epoch 49/300\n",
      "341/341 [==============================] - 0s - loss: 0.1471     \n",
      "Epoch 50/300\n",
      "341/341 [==============================] - 0s - loss: 0.1461     \n",
      "Epoch 51/300\n",
      "341/341 [==============================] - 0s - loss: 0.1447     \n",
      "Epoch 52/300\n",
      "341/341 [==============================] - 0s - loss: 0.1441     \n",
      "Epoch 53/300\n",
      "341/341 [==============================] - 0s - loss: 0.1430     \n",
      "Epoch 54/300\n",
      "341/341 [==============================] - 0s - loss: 0.1425     \n",
      "Epoch 55/300\n",
      "341/341 [==============================] - 0s - loss: 0.1414     \n",
      "Epoch 56/300\n",
      "341/341 [==============================] - 0s - loss: 0.1410     \n",
      "Epoch 57/300\n",
      "341/341 [==============================] - 0s - loss: 0.1398     \n",
      "Epoch 58/300\n",
      "341/341 [==============================] - 0s - loss: 0.1390     \n",
      "Epoch 59/300\n",
      "341/341 [==============================] - 0s - loss: 0.1379     \n",
      "Epoch 60/300\n",
      "341/341 [==============================] - 0s - loss: 0.1376     \n",
      "Epoch 61/300\n",
      "341/341 [==============================] - 0s - loss: 0.1369     \n",
      "Epoch 62/300\n",
      "341/341 [==============================] - 0s - loss: 0.1362     \n",
      "Epoch 63/300\n",
      "341/341 [==============================] - 0s - loss: 0.1349     \n",
      "Epoch 64/300\n",
      "341/341 [==============================] - 0s - loss: 0.1345     \n",
      "Epoch 65/300\n",
      "341/341 [==============================] - 0s - loss: 0.1338     \n",
      "Epoch 66/300\n",
      "341/341 [==============================] - 0s - loss: 0.1329     \n",
      "Epoch 67/300\n",
      "341/341 [==============================] - 0s - loss: 0.1326     \n",
      "Epoch 68/300\n",
      "341/341 [==============================] - 0s - loss: 0.1319     \n",
      "Epoch 69/300\n",
      "341/341 [==============================] - 0s - loss: 0.1312     \n",
      "Epoch 70/300\n",
      "341/341 [==============================] - 0s - loss: 0.1303     \n",
      "Epoch 71/300\n",
      "341/341 [==============================] - 0s - loss: 0.1292     \n",
      "Epoch 72/300\n",
      "341/341 [==============================] - 0s - loss: 0.1290     \n",
      "Epoch 73/300\n",
      "341/341 [==============================] - 0s - loss: 0.1282     \n",
      "Epoch 74/300\n",
      "341/341 [==============================] - 0s - loss: 0.1276     \n",
      "Epoch 75/300\n",
      "341/341 [==============================] - 0s - loss: 0.1269     \n",
      "Epoch 76/300\n",
      "341/341 [==============================] - 0s - loss: 0.1267     \n",
      "Epoch 77/300\n",
      "341/341 [==============================] - 0s - loss: 0.1262     \n",
      "Epoch 78/300\n",
      "341/341 [==============================] - 0s - loss: 0.1254     \n",
      "Epoch 79/300\n",
      "341/341 [==============================] - 0s - loss: 0.1245     \n",
      "Epoch 80/300\n",
      "341/341 [==============================] - 0s - loss: 0.1245     \n",
      "Epoch 81/300\n",
      "341/341 [==============================] - 0s - loss: 0.1236     \n",
      "Epoch 82/300\n",
      "341/341 [==============================] - 0s - loss: 0.1230     \n",
      "Epoch 83/300\n",
      "341/341 [==============================] - 0s - loss: 0.1226     \n",
      "Epoch 84/300\n",
      "341/341 [==============================] - 0s - loss: 0.1221     \n",
      "Epoch 85/300\n",
      "341/341 [==============================] - 0s - loss: 0.1215     \n",
      "Epoch 86/300\n",
      "341/341 [==============================] - 0s - loss: 0.1209     \n",
      "Epoch 87/300\n",
      "341/341 [==============================] - 0s - loss: 0.1209     \n",
      "Epoch 88/300\n",
      "341/341 [==============================] - 0s - loss: 0.1203     \n",
      "Epoch 89/300\n",
      "341/341 [==============================] - 0s - loss: 0.1194     \n",
      "Epoch 90/300\n",
      "341/341 [==============================] - 0s - loss: 0.1182     \n",
      "Epoch 91/300\n",
      "341/341 [==============================] - 0s - loss: 0.1180     \n",
      "Epoch 92/300\n",
      "341/341 [==============================] - 0s - loss: 0.1183     \n",
      "Epoch 93/300\n",
      "341/341 [==============================] - 0s - loss: 0.1173     \n",
      "Epoch 94/300\n",
      "341/341 [==============================] - 0s - loss: 0.1169     \n",
      "Epoch 95/300\n",
      "341/341 [==============================] - 0s - loss: 0.1162     \n",
      "Epoch 96/300\n",
      "341/341 [==============================] - 0s - loss: 0.1162     \n",
      "Epoch 97/300\n",
      "341/341 [==============================] - 0s - loss: 0.1160     \n",
      "Epoch 98/300\n",
      "341/341 [==============================] - 0s - loss: 0.1158     \n",
      "Epoch 99/300\n",
      "341/341 [==============================] - 0s - loss: 0.1146     \n",
      "Epoch 100/300\n",
      "341/341 [==============================] - 0s - loss: 0.1141     \n",
      "Epoch 101/300\n",
      "341/341 [==============================] - 0s - loss: 0.1136     \n",
      "Epoch 102/300\n",
      "341/341 [==============================] - 0s - loss: 0.1133     \n",
      "Epoch 103/300\n",
      "341/341 [==============================] - 0s - loss: 0.1126     \n",
      "Epoch 104/300\n",
      "341/341 [==============================] - 0s - loss: 0.1125     \n",
      "Epoch 105/300\n",
      "341/341 [==============================] - 0s - loss: 0.1120     \n",
      "Epoch 106/300\n",
      "341/341 [==============================] - 0s - loss: 0.1116     \n",
      "Epoch 107/300\n",
      "341/341 [==============================] - 0s - loss: 0.1110     \n",
      "Epoch 108/300\n",
      "341/341 [==============================] - 0s - loss: 0.1107     \n",
      "Epoch 109/300\n",
      "341/341 [==============================] - 0s - loss: 0.1103     \n",
      "Epoch 110/300\n",
      "341/341 [==============================] - 0s - loss: 0.1106     \n",
      "Epoch 111/300\n",
      "341/341 [==============================] - 0s - loss: 0.1092     \n",
      "Epoch 112/300\n",
      "341/341 [==============================] - 0s - loss: 0.1091     \n",
      "Epoch 113/300\n",
      "341/341 [==============================] - 0s - loss: 0.1082     \n",
      "Epoch 114/300\n",
      "341/341 [==============================] - 0s - loss: 0.1083     \n",
      "Epoch 115/300\n",
      "341/341 [==============================] - 0s - loss: 0.1073     \n",
      "Epoch 116/300\n",
      "341/341 [==============================] - 0s - loss: 0.1071     \n",
      "Epoch 117/300\n",
      "341/341 [==============================] - 0s - loss: 0.1073     \n",
      "Epoch 118/300\n",
      "341/341 [==============================] - 0s - loss: 0.1064     \n",
      "Epoch 119/300\n",
      "341/341 [==============================] - 0s - loss: 0.1062     \n",
      "Epoch 120/300\n",
      "341/341 [==============================] - 0s - loss: 0.1057     \n",
      "Epoch 121/300\n",
      "341/341 [==============================] - 0s - loss: 0.1056     \n",
      "Epoch 122/300\n",
      "341/341 [==============================] - 0s - loss: 0.1051     \n",
      "Epoch 123/300\n",
      "341/341 [==============================] - 0s - loss: 0.1050     \n",
      "Epoch 124/300\n",
      "341/341 [==============================] - 0s - loss: 0.1039     \n",
      "Epoch 125/300\n",
      "341/341 [==============================] - 0s - loss: 0.1041     \n",
      "Epoch 126/300\n",
      "341/341 [==============================] - 0s - loss: 0.1033     \n",
      "Epoch 127/300\n",
      "341/341 [==============================] - 0s - loss: 0.1030     \n",
      "Epoch 128/300\n",
      "341/341 [==============================] - 0s - loss: 0.1033     \n",
      "Epoch 129/300\n",
      "341/341 [==============================] - 0s - loss: 0.1029     \n",
      "Epoch 130/300\n",
      "341/341 [==============================] - 0s - loss: 0.1033     \n",
      "Epoch 131/300\n",
      "341/341 [==============================] - 0s - loss: 0.1018     \n",
      "Epoch 132/300\n",
      "341/341 [==============================] - 0s - loss: 0.1016     \n",
      "Epoch 133/300\n",
      "341/341 [==============================] - 0s - loss: 0.1014     \n",
      "Epoch 134/300\n",
      "341/341 [==============================] - 0s - loss: 0.1011     \n",
      "Epoch 135/300\n",
      "341/341 [==============================] - 0s - loss: 0.1008     \n",
      "Epoch 136/300\n",
      "341/341 [==============================] - 0s - loss: 0.1004     \n",
      "Epoch 137/300\n",
      "341/341 [==============================] - 0s - loss: 0.1000     \n",
      "Epoch 138/300\n",
      "341/341 [==============================] - 0s - loss: 0.0997     \n",
      "Epoch 139/300\n",
      "341/341 [==============================] - 0s - loss: 0.0992     \n",
      "Epoch 140/300\n",
      "341/341 [==============================] - 0s - loss: 0.0996     \n",
      "Epoch 141/300\n",
      "341/341 [==============================] - 0s - loss: 0.0989     \n",
      "Epoch 142/300\n",
      "341/341 [==============================] - 0s - loss: 0.0990     \n",
      "Epoch 143/300\n",
      "341/341 [==============================] - 0s - loss: 0.0980     \n",
      "Epoch 144/300\n",
      "341/341 [==============================] - 0s - loss: 0.0983     \n",
      "Epoch 145/300\n",
      "341/341 [==============================] - 0s - loss: 0.0979     \n",
      "Epoch 146/300\n",
      "341/341 [==============================] - 0s - loss: 0.0975     \n",
      "Epoch 147/300\n",
      "341/341 [==============================] - 0s - loss: 0.0969     \n",
      "Epoch 148/300\n",
      "341/341 [==============================] - 0s - loss: 0.0970     \n",
      "Epoch 149/300\n",
      "341/341 [==============================] - 0s - loss: 0.0968     \n",
      "Epoch 150/300\n",
      "341/341 [==============================] - 0s - loss: 0.0967     \n",
      "Epoch 151/300\n",
      "341/341 [==============================] - 0s - loss: 0.0961     \n",
      "Epoch 152/300\n",
      "341/341 [==============================] - 0s - loss: 0.0959     \n",
      "Epoch 153/300\n",
      "341/341 [==============================] - 0s - loss: 0.0955     \n",
      "Epoch 154/300\n",
      "341/341 [==============================] - 0s - loss: 0.0954     \n",
      "Epoch 155/300\n",
      "341/341 [==============================] - 0s - loss: 0.0955     \n",
      "Epoch 156/300\n",
      "341/341 [==============================] - 0s - loss: 0.0949     \n",
      "Epoch 157/300\n",
      "341/341 [==============================] - 0s - loss: 0.0942     \n",
      "Epoch 158/300\n",
      "341/341 [==============================] - 0s - loss: 0.0946     \n",
      "Epoch 159/300\n",
      "341/341 [==============================] - 0s - loss: 0.0941     \n",
      "Epoch 160/300\n",
      "341/341 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 161/300\n",
      "341/341 [==============================] - 0s - loss: 0.0938     \n",
      "Epoch 162/300\n",
      "341/341 [==============================] - 0s - loss: 0.0932     \n",
      "Epoch 163/300\n",
      "341/341 [==============================] - 0s - loss: 0.0925     \n",
      "Epoch 164/300\n",
      "341/341 [==============================] - 0s - loss: 0.0927     \n",
      "Epoch 165/300\n",
      "341/341 [==============================] - 0s - loss: 0.0927     \n",
      "Epoch 166/300\n",
      "341/341 [==============================] - 0s - loss: 0.0926     \n",
      "Epoch 167/300\n",
      "341/341 [==============================] - 0s - loss: 0.0921     \n",
      "Epoch 168/300\n",
      "341/341 [==============================] - 0s - loss: 0.0923     \n",
      "Epoch 169/300\n",
      "341/341 [==============================] - 0s - loss: 0.0912     \n",
      "Epoch 170/300\n",
      "341/341 [==============================] - 0s - loss: 0.0916     \n",
      "Epoch 171/300\n",
      "341/341 [==============================] - 0s - loss: 0.0915     \n",
      "Epoch 172/300\n",
      "341/341 [==============================] - 0s - loss: 0.0908     \n",
      "Epoch 173/300\n",
      "341/341 [==============================] - 0s - loss: 0.0902     \n",
      "Epoch 174/300\n",
      "341/341 [==============================] - 0s - loss: 0.0907     \n",
      "Epoch 175/300\n",
      "341/341 [==============================] - 0s - loss: 0.0903     \n",
      "Epoch 176/300\n",
      "341/341 [==============================] - 0s - loss: 0.0898     \n",
      "Epoch 177/300\n",
      "341/341 [==============================] - 0s - loss: 0.0899     \n",
      "Epoch 178/300\n",
      "341/341 [==============================] - 0s - loss: 0.0896     \n",
      "Epoch 179/300\n",
      "341/341 [==============================] - 0s - loss: 0.0893     \n",
      "Epoch 180/300\n",
      "341/341 [==============================] - 0s - loss: 0.0893     \n",
      "Epoch 181/300\n",
      "341/341 [==============================] - 0s - loss: 0.0890     \n",
      "Epoch 182/300\n",
      "341/341 [==============================] - 0s - loss: 0.0887     \n",
      "Epoch 183/300\n",
      "341/341 [==============================] - 0s - loss: 0.0885     \n",
      "Epoch 184/300\n",
      "341/341 [==============================] - 0s - loss: 0.0883     \n",
      "Epoch 185/300\n",
      "341/341 [==============================] - 0s - loss: 0.0877     \n",
      "Epoch 186/300\n",
      "341/341 [==============================] - 0s - loss: 0.0879     \n",
      "Epoch 187/300\n",
      "341/341 [==============================] - 0s - loss: 0.0880     \n",
      "Epoch 188/300\n",
      "341/341 [==============================] - 0s - loss: 0.0877     \n",
      "Epoch 189/300\n",
      "341/341 [==============================] - 0s - loss: 0.0871     \n",
      "Epoch 190/300\n",
      "341/341 [==============================] - 0s - loss: 0.0870     \n",
      "Epoch 191/300\n",
      "341/341 [==============================] - 0s - loss: 0.0869     \n",
      "Epoch 192/300\n",
      "341/341 [==============================] - 0s - loss: 0.0869     \n",
      "Epoch 193/300\n",
      "341/341 [==============================] - 0s - loss: 0.0866     \n",
      "Epoch 194/300\n",
      "341/341 [==============================] - 0s - loss: 0.0865     \n",
      "Epoch 195/300\n",
      "341/341 [==============================] - 0s - loss: 0.0864     \n",
      "Epoch 196/300\n",
      "341/341 [==============================] - 0s - loss: 0.0861     \n",
      "Epoch 197/300\n",
      "341/341 [==============================] - 0s - loss: 0.0860     \n",
      "Epoch 198/300\n",
      "341/341 [==============================] - 0s - loss: 0.0854     \n",
      "Epoch 199/300\n",
      "341/341 [==============================] - 0s - loss: 0.0857     \n",
      "Epoch 200/300\n",
      "341/341 [==============================] - 0s - loss: 0.0851     \n",
      "Epoch 201/300\n",
      "341/341 [==============================] - 0s - loss: 0.0848     \n",
      "Epoch 202/300\n",
      "341/341 [==============================] - 0s - loss: 0.0854     \n",
      "Epoch 203/300\n",
      "341/341 [==============================] - 0s - loss: 0.0845     \n",
      "Epoch 204/300\n",
      "341/341 [==============================] - 0s - loss: 0.0844     \n",
      "Epoch 205/300\n",
      "341/341 [==============================] - 0s - loss: 0.0845     \n",
      "Epoch 206/300\n",
      "341/341 [==============================] - 0s - loss: 0.0840     \n",
      "Epoch 207/300\n",
      "341/341 [==============================] - 0s - loss: 0.0837     \n",
      "Epoch 208/300\n",
      "341/341 [==============================] - 0s - loss: 0.0836     \n",
      "Epoch 209/300\n",
      "341/341 [==============================] - 0s - loss: 0.0833     \n",
      "Epoch 210/300\n",
      "341/341 [==============================] - 0s - loss: 0.0834     \n",
      "Epoch 211/300\n",
      "341/341 [==============================] - 0s - loss: 0.0833     \n",
      "Epoch 212/300\n",
      "341/341 [==============================] - 0s - loss: 0.0834     \n",
      "Epoch 213/300\n",
      "341/341 [==============================] - 0s - loss: 0.0831     \n",
      "Epoch 214/300\n",
      "341/341 [==============================] - 0s - loss: 0.0828     \n",
      "Epoch 215/300\n",
      "341/341 [==============================] - 0s - loss: 0.0822     \n",
      "Epoch 216/300\n",
      "341/341 [==============================] - 0s - loss: 0.0827     \n",
      "Epoch 217/300\n",
      "341/341 [==============================] - 0s - loss: 0.0821     \n",
      "Epoch 218/300\n",
      "341/341 [==============================] - 0s - loss: 0.0821     \n",
      "Epoch 219/300\n",
      "341/341 [==============================] - 0s - loss: 0.0820     \n",
      "Epoch 220/300\n",
      "341/341 [==============================] - 0s - loss: 0.0819     \n",
      "Epoch 221/300\n",
      "341/341 [==============================] - 0s - loss: 0.0816     \n",
      "Epoch 222/300\n",
      "341/341 [==============================] - 0s - loss: 0.0820     \n",
      "Epoch 223/300\n",
      "341/341 [==============================] - 0s - loss: 0.0814     \n",
      "Epoch 224/300\n",
      "341/341 [==============================] - 0s - loss: 0.0813     \n",
      "Epoch 225/300\n",
      "341/341 [==============================] - 0s - loss: 0.0811     \n",
      "Epoch 226/300\n",
      "341/341 [==============================] - 0s - loss: 0.0810     \n",
      "Epoch 227/300\n",
      "341/341 [==============================] - 0s - loss: 0.0808     \n",
      "Epoch 228/300\n",
      "341/341 [==============================] - 0s - loss: 0.0809     \n",
      "Epoch 229/300\n",
      "341/341 [==============================] - 0s - loss: 0.0805     \n",
      "Epoch 230/300\n",
      "341/341 [==============================] - 0s - loss: 0.0801     \n",
      "Epoch 231/300\n",
      "341/341 [==============================] - 0s - loss: 0.0802     \n",
      "Epoch 232/300\n",
      "341/341 [==============================] - 0s - loss: 0.0801     \n",
      "Epoch 233/300\n",
      "341/341 [==============================] - 0s - loss: 0.0798     \n",
      "Epoch 234/300\n",
      "341/341 [==============================] - 0s - loss: 0.0798     \n",
      "Epoch 235/300\n",
      "341/341 [==============================] - 0s - loss: 0.0794     \n",
      "Epoch 236/300\n",
      "341/341 [==============================] - 0s - loss: 0.0795     \n",
      "Epoch 237/300\n",
      "341/341 [==============================] - 0s - loss: 0.0791     \n",
      "Epoch 238/300\n",
      "341/341 [==============================] - 0s - loss: 0.0792     \n",
      "Epoch 239/300\n",
      "341/341 [==============================] - 0s - loss: 0.0792     \n",
      "Epoch 240/300\n",
      "341/341 [==============================] - 0s - loss: 0.0789     \n",
      "Epoch 241/300\n",
      "341/341 [==============================] - 0s - loss: 0.0791     \n",
      "Epoch 242/300\n",
      "341/341 [==============================] - 0s - loss: 0.0785     \n",
      "Epoch 243/300\n",
      "341/341 [==============================] - 0s - loss: 0.0783     \n",
      "Epoch 244/300\n",
      "341/341 [==============================] - 0s - loss: 0.0784     \n",
      "Epoch 245/300\n",
      "341/341 [==============================] - 0s - loss: 0.0780     \n",
      "Epoch 246/300\n",
      "341/341 [==============================] - 0s - loss: 0.0778     \n",
      "Epoch 247/300\n",
      "341/341 [==============================] - 0s - loss: 0.0780     \n",
      "Epoch 248/300\n",
      "341/341 [==============================] - 0s - loss: 0.0777     \n",
      "Epoch 249/300\n",
      "341/341 [==============================] - 0s - loss: 0.0775     \n",
      "Epoch 250/300\n",
      "341/341 [==============================] - 0s - loss: 0.0770     \n",
      "Epoch 251/300\n",
      "341/341 [==============================] - 0s - loss: 0.0771     \n",
      "Epoch 252/300\n",
      "341/341 [==============================] - 0s - loss: 0.0772     \n",
      "Epoch 253/300\n",
      "341/341 [==============================] - 0s - loss: 0.0769     \n",
      "Epoch 254/300\n",
      "341/341 [==============================] - 0s - loss: 0.0771     \n",
      "Epoch 255/300\n",
      "341/341 [==============================] - 0s - loss: 0.0767     \n",
      "Epoch 256/300\n",
      "341/341 [==============================] - 0s - loss: 0.0762     \n",
      "Epoch 257/300\n",
      "341/341 [==============================] - 0s - loss: 0.0762     \n",
      "Epoch 258/300\n",
      "341/341 [==============================] - 0s - loss: 0.0762     \n",
      "Epoch 259/300\n",
      "341/341 [==============================] - 0s - loss: 0.0760     \n",
      "Epoch 260/300\n",
      "341/341 [==============================] - 0s - loss: 0.0759     \n",
      "Epoch 261/300\n",
      "341/341 [==============================] - 0s - loss: 0.0758     \n",
      "Epoch 262/300\n",
      "341/341 [==============================] - 0s - loss: 0.0756     \n",
      "Epoch 263/300\n",
      "341/341 [==============================] - 0s - loss: 0.0755     \n",
      "Epoch 264/300\n",
      "341/341 [==============================] - 0s - loss: 0.0755     \n",
      "Epoch 265/300\n",
      "341/341 [==============================] - 0s - loss: 0.0750     \n",
      "Epoch 266/300\n",
      "341/341 [==============================] - 0s - loss: 0.0750     \n",
      "Epoch 267/300\n",
      "341/341 [==============================] - 0s - loss: 0.0750     \n",
      "Epoch 268/300\n",
      "341/341 [==============================] - 0s - loss: 0.0748     \n",
      "Epoch 269/300\n",
      "341/341 [==============================] - 0s - loss: 0.0748     \n",
      "Epoch 270/300\n",
      "341/341 [==============================] - 0s - loss: 0.0745     \n",
      "Epoch 271/300\n",
      "341/341 [==============================] - 0s - loss: 0.0747     \n",
      "Epoch 272/300\n",
      "341/341 [==============================] - 0s - loss: 0.0740     \n",
      "Epoch 273/300\n",
      "341/341 [==============================] - 0s - loss: 0.0737     \n",
      "Epoch 274/300\n",
      "341/341 [==============================] - 0s - loss: 0.0736     \n",
      "Epoch 275/300\n",
      "341/341 [==============================] - 0s - loss: 0.0740     \n",
      "Epoch 276/300\n",
      "341/341 [==============================] - 0s - loss: 0.0741     \n",
      "Epoch 277/300\n",
      "341/341 [==============================] - 0s - loss: 0.0738     \n",
      "Epoch 278/300\n",
      "341/341 [==============================] - 0s - loss: 0.0733     \n",
      "Epoch 279/300\n",
      "341/341 [==============================] - 0s - loss: 0.0733     \n",
      "Epoch 280/300\n",
      "341/341 [==============================] - 0s - loss: 0.0731     \n",
      "Epoch 281/300\n",
      "341/341 [==============================] - 0s - loss: 0.0729     \n",
      "Epoch 282/300\n",
      "341/341 [==============================] - 0s - loss: 0.0729     \n",
      "Epoch 283/300\n",
      "341/341 [==============================] - 0s - loss: 0.0726     \n",
      "Epoch 284/300\n",
      "341/341 [==============================] - 0s - loss: 0.0728     \n",
      "Epoch 285/300\n",
      "341/341 [==============================] - 0s - loss: 0.0728     \n",
      "Epoch 286/300\n",
      "341/341 [==============================] - 0s - loss: 0.0724     \n",
      "Epoch 287/300\n",
      "341/341 [==============================] - 0s - loss: 0.0721     \n",
      "Epoch 288/300\n",
      "341/341 [==============================] - 0s - loss: 0.0723     \n",
      "Epoch 289/300\n",
      "341/341 [==============================] - 0s - loss: 0.0719     \n",
      "Epoch 290/300\n",
      "341/341 [==============================] - 0s - loss: 0.0719     \n",
      "Epoch 291/300\n",
      "341/341 [==============================] - 0s - loss: 0.0714     \n",
      "Epoch 292/300\n",
      "341/341 [==============================] - 0s - loss: 0.0714     \n",
      "Epoch 293/300\n",
      "341/341 [==============================] - 0s - loss: 0.0713     \n",
      "Epoch 294/300\n",
      "341/341 [==============================] - 0s - loss: 0.0712     \n",
      "Epoch 295/300\n",
      "341/341 [==============================] - 0s - loss: 0.0716     \n",
      "Epoch 296/300\n",
      "341/341 [==============================] - 0s - loss: 0.0704     \n",
      "Epoch 297/300\n",
      "341/341 [==============================] - 0s - loss: 0.0707     \n",
      "Epoch 298/300\n",
      "341/341 [==============================] - 0s - loss: 0.0703     \n",
      "Epoch 299/300\n",
      "341/341 [==============================] - 0s - loss: 0.0707     \n",
      "Epoch 300/300\n",
      "341/341 [==============================] - 0s - loss: 0.0707     \n",
      "32/38 [========================>.....] - ETA: 0sEpoch 1/300\n",
      "341/341 [==============================] - 0s - loss: 0.9538     \n",
      "Epoch 2/300\n",
      "341/341 [==============================] - 0s - loss: 0.8481     \n",
      "Epoch 3/300\n",
      "341/341 [==============================] - 0s - loss: 0.7513     \n",
      "Epoch 4/300\n",
      "341/341 [==============================] - 0s - loss: 0.6585     \n",
      "Epoch 5/300\n",
      "341/341 [==============================] - 0s - loss: 0.5730     \n",
      "Epoch 6/300\n",
      "341/341 [==============================] - 0s - loss: 0.4973     \n",
      "Epoch 7/300\n",
      "341/341 [==============================] - 0s - loss: 0.4372     \n",
      "Epoch 8/300\n",
      "341/341 [==============================] - 0s - loss: 0.3903     \n",
      "Epoch 9/300\n",
      "341/341 [==============================] - 0s - loss: 0.3527     \n",
      "Epoch 10/300\n",
      "341/341 [==============================] - 0s - loss: 0.3219     \n",
      "Epoch 11/300\n",
      "341/341 [==============================] - 0s - loss: 0.2961     \n",
      "Epoch 12/300\n",
      "341/341 [==============================] - 0s - loss: 0.2747     \n",
      "Epoch 13/300\n",
      "341/341 [==============================] - 0s - loss: 0.2570     \n",
      "Epoch 14/300\n",
      "341/341 [==============================] - 0s - loss: 0.2423     \n",
      "Epoch 15/300\n",
      "341/341 [==============================] - 0s - loss: 0.2295     \n",
      "Epoch 16/300\n",
      "341/341 [==============================] - 0s - loss: 0.2188     \n",
      "Epoch 17/300\n",
      "341/341 [==============================] - 0s - loss: 0.2100     \n",
      "Epoch 18/300\n",
      "341/341 [==============================] - 0s - loss: 0.2031     \n",
      "Epoch 19/300\n",
      "341/341 [==============================] - 0s - loss: 0.1971     \n",
      "Epoch 20/300\n",
      "341/341 [==============================] - 0s - loss: 0.1916     \n",
      "Epoch 21/300\n",
      "341/341 [==============================] - 0s - loss: 0.1878     \n",
      "Epoch 22/300\n",
      "341/341 [==============================] - 0s - loss: 0.1838     \n",
      "Epoch 23/300\n",
      "341/341 [==============================] - 0s - loss: 0.1813     \n",
      "Epoch 24/300\n",
      "341/341 [==============================] - 0s - loss: 0.1782     \n",
      "Epoch 25/300\n",
      "341/341 [==============================] - 0s - loss: 0.1760     \n",
      "Epoch 26/300\n",
      "341/341 [==============================] - 0s - loss: 0.1740     \n",
      "Epoch 27/300\n",
      "341/341 [==============================] - 0s - loss: 0.1719     \n",
      "Epoch 28/300\n",
      "341/341 [==============================] - 0s - loss: 0.1698     \n",
      "Epoch 29/300\n",
      "341/341 [==============================] - 0s - loss: 0.1681     \n",
      "Epoch 30/300\n",
      "341/341 [==============================] - 0s - loss: 0.1662     \n",
      "Epoch 31/300\n",
      "341/341 [==============================] - 0s - loss: 0.1649     \n",
      "Epoch 32/300\n",
      "341/341 [==============================] - 0s - loss: 0.1634     \n",
      "Epoch 33/300\n",
      "341/341 [==============================] - 0s - loss: 0.1618     \n",
      "Epoch 34/300\n",
      "341/341 [==============================] - 0s - loss: 0.1604     \n",
      "Epoch 35/300\n",
      "341/341 [==============================] - 0s - loss: 0.1585     \n",
      "Epoch 36/300\n",
      "341/341 [==============================] - 0s - loss: 0.1577     \n",
      "Epoch 37/300\n",
      "341/341 [==============================] - 0s - loss: 0.1564     \n",
      "Epoch 38/300\n",
      "341/341 [==============================] - 0s - loss: 0.1553     \n",
      "Epoch 39/300\n",
      "341/341 [==============================] - 0s - loss: 0.1535     \n",
      "Epoch 40/300\n",
      "341/341 [==============================] - 0s - loss: 0.1530     \n",
      "Epoch 41/300\n",
      "341/341 [==============================] - 0s - loss: 0.1518     \n",
      "Epoch 42/300\n",
      "341/341 [==============================] - 0s - loss: 0.1507     \n",
      "Epoch 43/300\n",
      "341/341 [==============================] - 0s - loss: 0.1496     \n",
      "Epoch 44/300\n",
      "341/341 [==============================] - 0s - loss: 0.1488     \n",
      "Epoch 45/300\n",
      "341/341 [==============================] - 0s - loss: 0.1476     \n",
      "Epoch 46/300\n",
      "341/341 [==============================] - 0s - loss: 0.1469     \n",
      "Epoch 47/300\n",
      "341/341 [==============================] - 0s - loss: 0.1454     \n",
      "Epoch 48/300\n",
      "341/341 [==============================] - 0s - loss: 0.1448     \n",
      "Epoch 49/300\n",
      "341/341 [==============================] - 0s - loss: 0.1437     \n",
      "Epoch 50/300\n",
      "341/341 [==============================] - 0s - loss: 0.1428     \n",
      "Epoch 51/300\n",
      "341/341 [==============================] - 0s - loss: 0.1419     \n",
      "Epoch 52/300\n",
      "341/341 [==============================] - 0s - loss: 0.1413     \n",
      "Epoch 53/300\n",
      "341/341 [==============================] - 0s - loss: 0.1398     \n",
      "Epoch 54/300\n",
      "341/341 [==============================] - 0s - loss: 0.1395     \n",
      "Epoch 55/300\n",
      "341/341 [==============================] - 0s - loss: 0.1389     \n",
      "Epoch 56/300\n",
      "341/341 [==============================] - 0s - loss: 0.1371     \n",
      "Epoch 57/300\n",
      "341/341 [==============================] - 0s - loss: 0.1366     \n",
      "Epoch 58/300\n",
      "341/341 [==============================] - 0s - loss: 0.1364     \n",
      "Epoch 59/300\n",
      "341/341 [==============================] - 0s - loss: 0.1353     \n",
      "Epoch 60/300\n",
      "341/341 [==============================] - 0s - loss: 0.1343     \n",
      "Epoch 61/300\n",
      "341/341 [==============================] - 0s - loss: 0.1338     \n",
      "Epoch 62/300\n",
      "341/341 [==============================] - 0s - loss: 0.1334     \n",
      "Epoch 63/300\n",
      "341/341 [==============================] - 0s - loss: 0.1323     \n",
      "Epoch 64/300\n",
      "341/341 [==============================] - 0s - loss: 0.1316     \n",
      "Epoch 65/300\n",
      "341/341 [==============================] - 0s - loss: 0.1311     \n",
      "Epoch 66/300\n",
      "341/341 [==============================] - 0s - loss: 0.1307     \n",
      "Epoch 67/300\n",
      "341/341 [==============================] - 0s - loss: 0.1299     \n",
      "Epoch 68/300\n",
      "341/341 [==============================] - 0s - loss: 0.1293     \n",
      "Epoch 69/300\n",
      "341/341 [==============================] - 0s - loss: 0.1283     \n",
      "Epoch 70/300\n",
      "341/341 [==============================] - 0s - loss: 0.1279     \n",
      "Epoch 71/300\n",
      "341/341 [==============================] - 0s - loss: 0.1278     \n",
      "Epoch 72/300\n",
      "341/341 [==============================] - 0s - loss: 0.1272     \n",
      "Epoch 73/300\n",
      "341/341 [==============================] - 0s - loss: 0.1262     \n",
      "Epoch 74/300\n",
      "341/341 [==============================] - 0s - loss: 0.1253     \n",
      "Epoch 75/300\n",
      "341/341 [==============================] - 0s - loss: 0.1248     \n",
      "Epoch 76/300\n",
      "341/341 [==============================] - 0s - loss: 0.1238     \n",
      "Epoch 77/300\n",
      "341/341 [==============================] - 0s - loss: 0.1239     \n",
      "Epoch 78/300\n",
      "341/341 [==============================] - 0s - loss: 0.1232     \n",
      "Epoch 79/300\n",
      "341/341 [==============================] - 0s - loss: 0.1225     \n",
      "Epoch 80/300\n",
      "341/341 [==============================] - 0s - loss: 0.1217     \n",
      "Epoch 81/300\n",
      "341/341 [==============================] - 0s - loss: 0.1214     \n",
      "Epoch 82/300\n",
      "341/341 [==============================] - 0s - loss: 0.1210     \n",
      "Epoch 83/300\n",
      "341/341 [==============================] - 0s - loss: 0.1204     \n",
      "Epoch 84/300\n",
      "341/341 [==============================] - 0s - loss: 0.1200     \n",
      "Epoch 85/300\n",
      "341/341 [==============================] - 0s - loss: 0.1195     \n",
      "Epoch 86/300\n",
      "341/341 [==============================] - 0s - loss: 0.1191     \n",
      "Epoch 87/300\n",
      "341/341 [==============================] - 0s - loss: 0.1181     \n",
      "Epoch 88/300\n",
      "341/341 [==============================] - 0s - loss: 0.1181     \n",
      "Epoch 89/300\n",
      "341/341 [==============================] - 0s - loss: 0.1170     \n",
      "Epoch 90/300\n",
      "341/341 [==============================] - 0s - loss: 0.1170     \n",
      "Epoch 91/300\n",
      "341/341 [==============================] - 0s - loss: 0.1162     \n",
      "Epoch 92/300\n",
      "341/341 [==============================] - 0s - loss: 0.1160     \n",
      "Epoch 93/300\n",
      "341/341 [==============================] - 0s - loss: 0.1156     \n",
      "Epoch 94/300\n",
      "341/341 [==============================] - 0s - loss: 0.1154     \n",
      "Epoch 95/300\n",
      "341/341 [==============================] - 0s - loss: 0.1150     \n",
      "Epoch 96/300\n",
      "341/341 [==============================] - 0s - loss: 0.1141     \n",
      "Epoch 97/300\n",
      "341/341 [==============================] - 0s - loss: 0.1134     \n",
      "Epoch 98/300\n",
      "341/341 [==============================] - 0s - loss: 0.1140     \n",
      "Epoch 99/300\n",
      "341/341 [==============================] - 0s - loss: 0.1131     \n",
      "Epoch 100/300\n",
      "341/341 [==============================] - 0s - loss: 0.1123     \n",
      "Epoch 101/300\n",
      "341/341 [==============================] - 0s - loss: 0.1117     \n",
      "Epoch 102/300\n",
      "341/341 [==============================] - 0s - loss: 0.1120     \n",
      "Epoch 103/300\n",
      "341/341 [==============================] - 0s - loss: 0.1112     \n",
      "Epoch 104/300\n",
      "341/341 [==============================] - 0s - loss: 0.1112     \n",
      "Epoch 105/300\n",
      "341/341 [==============================] - 0s - loss: 0.1105     \n",
      "Epoch 106/300\n",
      "341/341 [==============================] - 0s - loss: 0.1104     \n",
      "Epoch 107/300\n",
      "341/341 [==============================] - 0s - loss: 0.1099     \n",
      "Epoch 108/300\n",
      "341/341 [==============================] - 0s - loss: 0.1092     \n",
      "Epoch 109/300\n",
      "341/341 [==============================] - 0s - loss: 0.1087     \n",
      "Epoch 110/300\n",
      "341/341 [==============================] - 0s - loss: 0.1086     \n",
      "Epoch 111/300\n",
      "341/341 [==============================] - 0s - loss: 0.1082     \n",
      "Epoch 112/300\n",
      "341/341 [==============================] - 0s - loss: 0.1072     \n",
      "Epoch 113/300\n",
      "341/341 [==============================] - 0s - loss: 0.1073     \n",
      "Epoch 114/300\n",
      "341/341 [==============================] - 0s - loss: 0.1069     \n",
      "Epoch 115/300\n",
      "341/341 [==============================] - 0s - loss: 0.1063     \n",
      "Epoch 116/300\n",
      "341/341 [==============================] - 0s - loss: 0.1063     \n",
      "Epoch 117/300\n",
      "341/341 [==============================] - 0s - loss: 0.1059     \n",
      "Epoch 118/300\n",
      "341/341 [==============================] - 0s - loss: 0.1057     \n",
      "Epoch 119/300\n",
      "341/341 [==============================] - 0s - loss: 0.1049     \n",
      "Epoch 120/300\n",
      "341/341 [==============================] - 0s - loss: 0.1050     \n",
      "Epoch 121/300\n",
      "341/341 [==============================] - 0s - loss: 0.1046     \n",
      "Epoch 122/300\n",
      "341/341 [==============================] - 0s - loss: 0.1043     \n",
      "Epoch 123/300\n",
      "341/341 [==============================] - 0s - loss: 0.1038     \n",
      "Epoch 124/300\n",
      "341/341 [==============================] - 0s - loss: 0.1033     \n",
      "Epoch 125/300\n",
      "341/341 [==============================] - 0s - loss: 0.1032     \n",
      "Epoch 126/300\n",
      "341/341 [==============================] - 0s - loss: 0.1026     \n",
      "Epoch 127/300\n",
      "341/341 [==============================] - 0s - loss: 0.1027     \n",
      "Epoch 128/300\n",
      "341/341 [==============================] - 0s - loss: 0.1022     \n",
      "Epoch 129/300\n",
      "341/341 [==============================] - 0s - loss: 0.1017     \n",
      "Epoch 130/300\n",
      "341/341 [==============================] - 0s - loss: 0.1015     \n",
      "Epoch 131/300\n",
      "341/341 [==============================] - 0s - loss: 0.1010     \n",
      "Epoch 132/300\n",
      "341/341 [==============================] - 0s - loss: 0.1005     \n",
      "Epoch 133/300\n",
      "341/341 [==============================] - 0s - loss: 0.1004     \n",
      "Epoch 134/300\n",
      "341/341 [==============================] - 0s - loss: 0.1002     \n",
      "Epoch 135/300\n",
      "341/341 [==============================] - 0s - loss: 0.1000     \n",
      "Epoch 136/300\n",
      "341/341 [==============================] - 0s - loss: 0.0998     \n",
      "Epoch 137/300\n",
      "341/341 [==============================] - 0s - loss: 0.0993     \n",
      "Epoch 138/300\n",
      "341/341 [==============================] - 0s - loss: 0.0990     \n",
      "Epoch 139/300\n",
      "341/341 [==============================] - 0s - loss: 0.0991     \n",
      "Epoch 140/300\n",
      "341/341 [==============================] - 0s - loss: 0.0980     \n",
      "Epoch 141/300\n",
      "341/341 [==============================] - 0s - loss: 0.0978     \n",
      "Epoch 142/300\n",
      "341/341 [==============================] - 0s - loss: 0.0979     \n",
      "Epoch 143/300\n",
      "341/341 [==============================] - 0s - loss: 0.0971     \n",
      "Epoch 144/300\n",
      "341/341 [==============================] - 0s - loss: 0.0968     \n",
      "Epoch 145/300\n",
      "341/341 [==============================] - 0s - loss: 0.0971     \n",
      "Epoch 146/300\n",
      "341/341 [==============================] - 0s - loss: 0.0963     \n",
      "Epoch 147/300\n",
      "341/341 [==============================] - 0s - loss: 0.0965     \n",
      "Epoch 148/300\n",
      "341/341 [==============================] - 0s - loss: 0.0955     \n",
      "Epoch 149/300\n",
      "341/341 [==============================] - 0s - loss: 0.0958     \n",
      "Epoch 150/300\n",
      "341/341 [==============================] - 0s - loss: 0.0950     \n",
      "Epoch 151/300\n",
      "341/341 [==============================] - 0s - loss: 0.0954     \n",
      "Epoch 152/300\n",
      "341/341 [==============================] - 0s - loss: 0.0949     \n",
      "Epoch 153/300\n",
      "341/341 [==============================] - 0s - loss: 0.0944     \n",
      "Epoch 154/300\n",
      "341/341 [==============================] - 0s - loss: 0.0947     \n",
      "Epoch 155/300\n",
      "341/341 [==============================] - 0s - loss: 0.0942     \n",
      "Epoch 156/300\n",
      "341/341 [==============================] - 0s - loss: 0.0938     \n",
      "Epoch 157/300\n",
      "341/341 [==============================] - 0s - loss: 0.0936     \n",
      "Epoch 158/300\n",
      "341/341 [==============================] - 0s - loss: 0.0933     \n",
      "Epoch 159/300\n",
      "341/341 [==============================] - 0s - loss: 0.0930     \n",
      "Epoch 160/300\n",
      "341/341 [==============================] - 0s - loss: 0.0926     \n",
      "Epoch 161/300\n",
      "341/341 [==============================] - 0s - loss: 0.0931     \n",
      "Epoch 162/300\n",
      "341/341 [==============================] - 0s - loss: 0.0924     \n",
      "Epoch 163/300\n",
      "341/341 [==============================] - 0s - loss: 0.0923     \n",
      "Epoch 164/300\n",
      "341/341 [==============================] - 0s - loss: 0.0925     \n",
      "Epoch 165/300\n",
      "341/341 [==============================] - 0s - loss: 0.0912     \n",
      "Epoch 166/300\n",
      "341/341 [==============================] - 0s - loss: 0.0913     \n",
      "Epoch 167/300\n",
      "341/341 [==============================] - 0s - loss: 0.0908     \n",
      "Epoch 168/300\n",
      "341/341 [==============================] - 0s - loss: 0.0912     \n",
      "Epoch 169/300\n",
      "341/341 [==============================] - 0s - loss: 0.0906     \n",
      "Epoch 170/300\n",
      "341/341 [==============================] - 0s - loss: 0.0905     \n",
      "Epoch 171/300\n",
      "341/341 [==============================] - 0s - loss: 0.0900     \n",
      "Epoch 172/300\n",
      "341/341 [==============================] - 0s - loss: 0.0895     \n",
      "Epoch 173/300\n",
      "341/341 [==============================] - 0s - loss: 0.0897     \n",
      "Epoch 174/300\n",
      "341/341 [==============================] - 0s - loss: 0.0896     \n",
      "Epoch 175/300\n",
      "341/341 [==============================] - 0s - loss: 0.0894     \n",
      "Epoch 176/300\n",
      "341/341 [==============================] - 0s - loss: 0.0893     \n",
      "Epoch 177/300\n",
      "341/341 [==============================] - 0s - loss: 0.0884     \n",
      "Epoch 178/300\n",
      "341/341 [==============================] - 0s - loss: 0.0886     \n",
      "Epoch 179/300\n",
      "341/341 [==============================] - 0s - loss: 0.0884     \n",
      "Epoch 180/300\n",
      "341/341 [==============================] - 0s - loss: 0.0883     \n",
      "Epoch 181/300\n",
      "341/341 [==============================] - 0s - loss: 0.0875     \n",
      "Epoch 182/300\n",
      "341/341 [==============================] - 0s - loss: 0.0880     \n",
      "Epoch 183/300\n",
      "341/341 [==============================] - 0s - loss: 0.0871     \n",
      "Epoch 184/300\n",
      "341/341 [==============================] - 0s - loss: 0.0868     \n",
      "Epoch 185/300\n",
      "341/341 [==============================] - 0s - loss: 0.0866     \n",
      "Epoch 186/300\n",
      "341/341 [==============================] - 0s - loss: 0.0868     \n",
      "Epoch 187/300\n",
      "341/341 [==============================] - 0s - loss: 0.0864     \n",
      "Epoch 188/300\n",
      "341/341 [==============================] - 0s - loss: 0.0863     \n",
      "Epoch 189/300\n",
      "341/341 [==============================] - 0s - loss: 0.0858     \n",
      "Epoch 190/300\n",
      "341/341 [==============================] - 0s - loss: 0.0862     \n",
      "Epoch 191/300\n",
      "341/341 [==============================] - 0s - loss: 0.0860     \n",
      "Epoch 192/300\n",
      "341/341 [==============================] - 0s - loss: 0.0854     \n",
      "Epoch 193/300\n",
      "341/341 [==============================] - 0s - loss: 0.0858     \n",
      "Epoch 194/300\n",
      "341/341 [==============================] - 0s - loss: 0.0853     \n",
      "Epoch 195/300\n",
      "341/341 [==============================] - 0s - loss: 0.0849     \n",
      "Epoch 196/300\n",
      "341/341 [==============================] - 0s - loss: 0.0848     \n",
      "Epoch 197/300\n",
      "341/341 [==============================] - 0s - loss: 0.0841     \n",
      "Epoch 198/300\n",
      "341/341 [==============================] - 0s - loss: 0.0843     \n",
      "Epoch 199/300\n",
      "341/341 [==============================] - 0s - loss: 0.0840     \n",
      "Epoch 200/300\n",
      "341/341 [==============================] - 0s - loss: 0.0839     \n",
      "Epoch 201/300\n",
      "341/341 [==============================] - 0s - loss: 0.0834     \n",
      "Epoch 202/300\n",
      "341/341 [==============================] - 0s - loss: 0.0837     \n",
      "Epoch 203/300\n",
      "341/341 [==============================] - 0s - loss: 0.0835     \n",
      "Epoch 204/300\n",
      "341/341 [==============================] - 0s - loss: 0.0835     \n",
      "Epoch 205/300\n",
      "341/341 [==============================] - 0s - loss: 0.0828     \n",
      "Epoch 206/300\n",
      "341/341 [==============================] - 0s - loss: 0.0829     \n",
      "Epoch 207/300\n",
      "341/341 [==============================] - 0s - loss: 0.0824     \n",
      "Epoch 208/300\n",
      "341/341 [==============================] - 0s - loss: 0.0823     \n",
      "Epoch 209/300\n",
      "341/341 [==============================] - 0s - loss: 0.0821     \n",
      "Epoch 210/300\n",
      "341/341 [==============================] - 0s - loss: 0.0818     \n",
      "Epoch 211/300\n",
      "341/341 [==============================] - 0s - loss: 0.0820     \n",
      "Epoch 212/300\n",
      "341/341 [==============================] - 0s - loss: 0.0818     \n",
      "Epoch 213/300\n",
      "341/341 [==============================] - 0s - loss: 0.0814     \n",
      "Epoch 214/300\n",
      "341/341 [==============================] - 0s - loss: 0.0812     \n",
      "Epoch 215/300\n",
      "341/341 [==============================] - 0s - loss: 0.0811     \n",
      "Epoch 216/300\n",
      "341/341 [==============================] - 0s - loss: 0.0807     \n",
      "Epoch 217/300\n",
      "341/341 [==============================] - 0s - loss: 0.0808     \n",
      "Epoch 218/300\n",
      "341/341 [==============================] - 0s - loss: 0.0805     \n",
      "Epoch 219/300\n",
      "341/341 [==============================] - 0s - loss: 0.0799     \n",
      "Epoch 220/300\n",
      "341/341 [==============================] - 0s - loss: 0.0801     \n",
      "Epoch 221/300\n",
      "341/341 [==============================] - 0s - loss: 0.0798     \n",
      "Epoch 222/300\n",
      "341/341 [==============================] - 0s - loss: 0.0799     \n",
      "Epoch 223/300\n",
      "341/341 [==============================] - 0s - loss: 0.0798     \n",
      "Epoch 224/300\n",
      "341/341 [==============================] - 0s - loss: 0.0794     \n",
      "Epoch 225/300\n",
      "341/341 [==============================] - 0s - loss: 0.0792     \n",
      "Epoch 226/300\n",
      "341/341 [==============================] - 0s - loss: 0.0787     \n",
      "Epoch 227/300\n",
      "341/341 [==============================] - 0s - loss: 0.0788     \n",
      "Epoch 228/300\n",
      "341/341 [==============================] - 0s - loss: 0.0787     \n",
      "Epoch 229/300\n",
      "341/341 [==============================] - 0s - loss: 0.0788     \n",
      "Epoch 230/300\n",
      "341/341 [==============================] - 0s - loss: 0.0783     \n",
      "Epoch 231/300\n",
      "341/341 [==============================] - 0s - loss: 0.0780     \n",
      "Epoch 232/300\n",
      "341/341 [==============================] - 0s - loss: 0.0780     \n",
      "Epoch 233/300\n",
      "341/341 [==============================] - 0s - loss: 0.0779     \n",
      "Epoch 234/300\n",
      "341/341 [==============================] - 0s - loss: 0.0778     \n",
      "Epoch 235/300\n",
      "341/341 [==============================] - 0s - loss: 0.0776     \n",
      "Epoch 236/300\n",
      "341/341 [==============================] - 0s - loss: 0.0777     \n",
      "Epoch 237/300\n",
      "341/341 [==============================] - 0s - loss: 0.0772     \n",
      "Epoch 238/300\n",
      "341/341 [==============================] - 0s - loss: 0.0771     \n",
      "Epoch 239/300\n",
      "341/341 [==============================] - 0s - loss: 0.0770     \n",
      "Epoch 240/300\n",
      "341/341 [==============================] - 0s - loss: 0.0764     \n",
      "Epoch 241/300\n",
      "341/341 [==============================] - 0s - loss: 0.0765     \n",
      "Epoch 242/300\n",
      "341/341 [==============================] - 0s - loss: 0.0763     \n",
      "Epoch 243/300\n",
      "341/341 [==============================] - 0s - loss: 0.0757     \n",
      "Epoch 244/300\n",
      "341/341 [==============================] - 0s - loss: 0.0757     \n",
      "Epoch 245/300\n",
      "341/341 [==============================] - 0s - loss: 0.0757     \n",
      "Epoch 246/300\n",
      "341/341 [==============================] - 0s - loss: 0.0755     \n",
      "Epoch 247/300\n",
      "341/341 [==============================] - 0s - loss: 0.0755     \n",
      "Epoch 248/300\n",
      "341/341 [==============================] - 0s - loss: 0.0753     \n",
      "Epoch 249/300\n",
      "341/341 [==============================] - 0s - loss: 0.0750     \n",
      "Epoch 250/300\n",
      "341/341 [==============================] - 0s - loss: 0.0755     \n",
      "Epoch 251/300\n",
      "341/341 [==============================] - 0s - loss: 0.0748     \n",
      "Epoch 252/300\n",
      "341/341 [==============================] - 0s - loss: 0.0751     \n",
      "Epoch 253/300\n",
      "341/341 [==============================] - 0s - loss: 0.0745     \n",
      "Epoch 254/300\n",
      "341/341 [==============================] - 0s - loss: 0.0743     \n",
      "Epoch 255/300\n",
      "341/341 [==============================] - 0s - loss: 0.0738     \n",
      "Epoch 256/300\n",
      "341/341 [==============================] - 0s - loss: 0.0740     \n",
      "Epoch 257/300\n",
      "341/341 [==============================] - 0s - loss: 0.0738     \n",
      "Epoch 258/300\n",
      "341/341 [==============================] - 0s - loss: 0.0738     \n",
      "Epoch 259/300\n",
      "341/341 [==============================] - 0s - loss: 0.0733     \n",
      "Epoch 260/300\n",
      "341/341 [==============================] - 0s - loss: 0.0734     \n",
      "Epoch 261/300\n",
      "341/341 [==============================] - 0s - loss: 0.0730     \n",
      "Epoch 262/300\n",
      "341/341 [==============================] - 0s - loss: 0.0730     \n",
      "Epoch 263/300\n",
      "341/341 [==============================] - 0s - loss: 0.0732     \n",
      "Epoch 264/300\n",
      "341/341 [==============================] - 0s - loss: 0.0727     \n",
      "Epoch 265/300\n",
      "341/341 [==============================] - 0s - loss: 0.0722     \n",
      "Epoch 266/300\n",
      "341/341 [==============================] - 0s - loss: 0.0728     \n",
      "Epoch 267/300\n",
      "341/341 [==============================] - 0s - loss: 0.0721     \n",
      "Epoch 268/300\n",
      "341/341 [==============================] - 0s - loss: 0.0722     \n",
      "Epoch 269/300\n",
      "341/341 [==============================] - 0s - loss: 0.0722     \n",
      "Epoch 270/300\n",
      "341/341 [==============================] - 0s - loss: 0.0717     \n",
      "Epoch 271/300\n",
      "341/341 [==============================] - 0s - loss: 0.0718     \n",
      "Epoch 272/300\n",
      "341/341 [==============================] - 0s - loss: 0.0713     \n",
      "Epoch 273/300\n",
      "341/341 [==============================] - 0s - loss: 0.0713     \n",
      "Epoch 274/300\n",
      "341/341 [==============================] - 0s - loss: 0.0712     \n",
      "Epoch 275/300\n",
      "341/341 [==============================] - 0s - loss: 0.0710     \n",
      "Epoch 276/300\n",
      "341/341 [==============================] - 0s - loss: 0.0706     \n",
      "Epoch 277/300\n",
      "341/341 [==============================] - 0s - loss: 0.0708     \n",
      "Epoch 278/300\n",
      "341/341 [==============================] - 0s - loss: 0.0706     \n",
      "Epoch 279/300\n",
      "341/341 [==============================] - 0s - loss: 0.0703     \n",
      "Epoch 280/300\n",
      "341/341 [==============================] - 0s - loss: 0.0702     \n",
      "Epoch 281/300\n",
      "341/341 [==============================] - 0s - loss: 0.0703     \n",
      "Epoch 282/300\n",
      "341/341 [==============================] - 0s - loss: 0.0701     \n",
      "Epoch 283/300\n",
      "341/341 [==============================] - 0s - loss: 0.0698     \n",
      "Epoch 284/300\n",
      "341/341 [==============================] - 0s - loss: 0.0700     \n",
      "Epoch 285/300\n",
      "341/341 [==============================] - 0s - loss: 0.0697     \n",
      "Epoch 286/300\n",
      "341/341 [==============================] - 0s - loss: 0.0695     \n",
      "Epoch 287/300\n",
      "341/341 [==============================] - 0s - loss: 0.0693     \n",
      "Epoch 288/300\n",
      "341/341 [==============================] - 0s - loss: 0.0690     \n",
      "Epoch 289/300\n",
      "341/341 [==============================] - 0s - loss: 0.0688     \n",
      "Epoch 290/300\n",
      "341/341 [==============================] - 0s - loss: 0.0689     \n",
      "Epoch 291/300\n",
      "341/341 [==============================] - 0s - loss: 0.0687     \n",
      "Epoch 292/300\n",
      "341/341 [==============================] - 0s - loss: 0.0687     \n",
      "Epoch 293/300\n",
      "341/341 [==============================] - 0s - loss: 0.0685     \n",
      "Epoch 294/300\n",
      "341/341 [==============================] - 0s - loss: 0.0685     \n",
      "Epoch 295/300\n",
      "341/341 [==============================] - 0s - loss: 0.0683     \n",
      "Epoch 296/300\n",
      "341/341 [==============================] - 0s - loss: 0.0685     \n",
      "Epoch 297/300\n",
      "341/341 [==============================] - 0s - loss: 0.0682     \n",
      "Epoch 298/300\n",
      "341/341 [==============================] - 0s - loss: 0.0681     \n",
      "Epoch 299/300\n",
      "341/341 [==============================] - 0s - loss: 0.0676     \n",
      "Epoch 300/300\n",
      "341/341 [==============================] - 0s - loss: 0.0679     \n",
      "32/38 [========================>.....] - ETA: 0sEpoch 1/300\n",
      "341/341 [==============================] - 0s - loss: 1.0126     \n",
      "Epoch 2/300\n",
      "341/341 [==============================] - 0s - loss: 0.8939     \n",
      "Epoch 3/300\n",
      "341/341 [==============================] - 0s - loss: 0.7819     \n",
      "Epoch 4/300\n",
      "341/341 [==============================] - 0s - loss: 0.6787     \n",
      "Epoch 5/300\n",
      "341/341 [==============================] - 0s - loss: 0.5855     \n",
      "Epoch 6/300\n",
      "341/341 [==============================] - 0s - loss: 0.5055     \n",
      "Epoch 7/300\n",
      "341/341 [==============================] - 0s - loss: 0.4420     \n",
      "Epoch 8/300\n",
      "341/341 [==============================] - 0s - loss: 0.3926     \n",
      "Epoch 9/300\n",
      "341/341 [==============================] - 0s - loss: 0.3546     \n",
      "Epoch 10/300\n",
      "341/341 [==============================] - 0s - loss: 0.3214     \n",
      "Epoch 11/300\n",
      "341/341 [==============================] - 0s - loss: 0.2951     \n",
      "Epoch 12/300\n",
      "341/341 [==============================] - 0s - loss: 0.2738     \n",
      "Epoch 13/300\n",
      "341/341 [==============================] - 0s - loss: 0.2556     \n",
      "Epoch 14/300\n",
      "341/341 [==============================] - 0s - loss: 0.2402     \n",
      "Epoch 15/300\n",
      "341/341 [==============================] - 0s - loss: 0.2266     \n",
      "Epoch 16/300\n",
      "341/341 [==============================] - 0s - loss: 0.2159     \n",
      "Epoch 17/300\n",
      "341/341 [==============================] - 0s - loss: 0.2065     \n",
      "Epoch 18/300\n",
      "341/341 [==============================] - 0s - loss: 0.1984     \n",
      "Epoch 19/300\n",
      "341/341 [==============================] - 0s - loss: 0.1922     \n",
      "Epoch 20/300\n",
      "341/341 [==============================] - 0s - loss: 0.1860     \n",
      "Epoch 21/300\n",
      "341/341 [==============================] - 0s - loss: 0.1810     \n",
      "Epoch 22/300\n",
      "341/341 [==============================] - 0s - loss: 0.1764     \n",
      "Epoch 23/300\n",
      "341/341 [==============================] - 0s - loss: 0.1733     \n",
      "Epoch 24/300\n",
      "341/341 [==============================] - 0s - loss: 0.1695     \n",
      "Epoch 25/300\n",
      "341/341 [==============================] - 0s - loss: 0.1667     \n",
      "Epoch 26/300\n",
      "341/341 [==============================] - 0s - loss: 0.1638     \n",
      "Epoch 27/300\n",
      "341/341 [==============================] - 0s - loss: 0.1614     \n",
      "Epoch 28/300\n",
      "341/341 [==============================] - 0s - loss: 0.1592     \n",
      "Epoch 29/300\n",
      "341/341 [==============================] - 0s - loss: 0.1569     \n",
      "Epoch 30/300\n",
      "341/341 [==============================] - 0s - loss: 0.1547     \n",
      "Epoch 31/300\n",
      "341/341 [==============================] - 0s - loss: 0.1532     \n",
      "Epoch 32/300\n",
      "341/341 [==============================] - 0s - loss: 0.1513     \n",
      "Epoch 33/300\n",
      "341/341 [==============================] - 0s - loss: 0.1496     \n",
      "Epoch 34/300\n",
      "341/341 [==============================] - 0s - loss: 0.1480     \n",
      "Epoch 35/300\n",
      "341/341 [==============================] - 0s - loss: 0.1464     \n",
      "Epoch 36/300\n",
      "341/341 [==============================] - 0s - loss: 0.1452     \n",
      "Epoch 37/300\n",
      "341/341 [==============================] - 0s - loss: 0.1440     \n",
      "Epoch 38/300\n",
      "341/341 [==============================] - 0s - loss: 0.1425     \n",
      "Epoch 39/300\n",
      "341/341 [==============================] - 0s - loss: 0.1409     \n",
      "Epoch 40/300\n",
      "341/341 [==============================] - 0s - loss: 0.1399     \n",
      "Epoch 41/300\n",
      "341/341 [==============================] - 0s - loss: 0.1387     \n",
      "Epoch 42/300\n",
      "341/341 [==============================] - 0s - loss: 0.1375     \n",
      "Epoch 43/300\n",
      "341/341 [==============================] - 0s - loss: 0.1365     \n",
      "Epoch 44/300\n",
      "341/341 [==============================] - 0s - loss: 0.1352     \n",
      "Epoch 45/300\n",
      "341/341 [==============================] - 0s - loss: 0.1345     \n",
      "Epoch 46/300\n",
      "341/341 [==============================] - 0s - loss: 0.1335     \n",
      "Epoch 47/300\n",
      "341/341 [==============================] - 0s - loss: 0.1327     \n",
      "Epoch 48/300\n",
      "341/341 [==============================] - 0s - loss: 0.1317     \n",
      "Epoch 49/300\n",
      "341/341 [==============================] - 0s - loss: 0.1306     \n",
      "Epoch 50/300\n",
      "341/341 [==============================] - 0s - loss: 0.1297     \n",
      "Epoch 51/300\n",
      "341/341 [==============================] - 0s - loss: 0.1290     \n",
      "Epoch 52/300\n",
      "341/341 [==============================] - 0s - loss: 0.1280     \n",
      "Epoch 53/300\n",
      "341/341 [==============================] - 0s - loss: 0.1274     \n",
      "Epoch 54/300\n",
      "341/341 [==============================] - 0s - loss: 0.1266     \n",
      "Epoch 55/300\n",
      "341/341 [==============================] - 0s - loss: 0.1258     \n",
      "Epoch 56/300\n",
      "341/341 [==============================] - 0s - loss: 0.1251     \n",
      "Epoch 57/300\n",
      "341/341 [==============================] - 0s - loss: 0.1244     \n",
      "Epoch 58/300\n",
      "341/341 [==============================] - 0s - loss: 0.1240     \n",
      "Epoch 59/300\n",
      "341/341 [==============================] - 0s - loss: 0.1232     \n",
      "Epoch 60/300\n",
      "341/341 [==============================] - 0s - loss: 0.1223     \n",
      "Epoch 61/300\n",
      "341/341 [==============================] - 0s - loss: 0.1216     \n",
      "Epoch 62/300\n",
      "341/341 [==============================] - 0s - loss: 0.1211     \n",
      "Epoch 63/300\n",
      "341/341 [==============================] - 0s - loss: 0.1203     \n",
      "Epoch 64/300\n",
      "341/341 [==============================] - 0s - loss: 0.1199     \n",
      "Epoch 65/300\n",
      "341/341 [==============================] - 0s - loss: 0.1194     \n",
      "Epoch 66/300\n",
      "341/341 [==============================] - 0s - loss: 0.1187     \n",
      "Epoch 67/300\n",
      "341/341 [==============================] - 0s - loss: 0.1182     \n",
      "Epoch 68/300\n",
      "341/341 [==============================] - 0s - loss: 0.1175     \n",
      "Epoch 69/300\n",
      "341/341 [==============================] - 0s - loss: 0.1166     \n",
      "Epoch 70/300\n",
      "341/341 [==============================] - 0s - loss: 0.1164     \n",
      "Epoch 71/300\n",
      "341/341 [==============================] - 0s - loss: 0.1156     \n",
      "Epoch 72/300\n",
      "341/341 [==============================] - 0s - loss: 0.1150     \n",
      "Epoch 73/300\n",
      "341/341 [==============================] - 0s - loss: 0.1144     \n",
      "Epoch 74/300\n",
      "341/341 [==============================] - 0s - loss: 0.1141     \n",
      "Epoch 75/300\n",
      "341/341 [==============================] - 0s - loss: 0.1135     \n",
      "Epoch 76/300\n",
      "341/341 [==============================] - 0s - loss: 0.1130     \n",
      "Epoch 77/300\n",
      "341/341 [==============================] - 0s - loss: 0.1126     \n",
      "Epoch 78/300\n",
      "341/341 [==============================] - 0s - loss: 0.1120     \n",
      "Epoch 79/300\n",
      "341/341 [==============================] - 0s - loss: 0.1116     \n",
      "Epoch 80/300\n",
      "341/341 [==============================] - 0s - loss: 0.1113     \n",
      "Epoch 81/300\n",
      "341/341 [==============================] - 0s - loss: 0.1109     \n",
      "Epoch 82/300\n",
      "341/341 [==============================] - 0s - loss: 0.1101     \n",
      "Epoch 83/300\n",
      "341/341 [==============================] - 0s - loss: 0.1096     \n",
      "Epoch 84/300\n",
      "341/341 [==============================] - 0s - loss: 0.1091     \n",
      "Epoch 85/300\n",
      "341/341 [==============================] - 0s - loss: 0.1089     \n",
      "Epoch 86/300\n",
      "341/341 [==============================] - 0s - loss: 0.1084     \n",
      "Epoch 87/300\n",
      "341/341 [==============================] - 0s - loss: 0.1082     \n",
      "Epoch 88/300\n",
      "341/341 [==============================] - 0s - loss: 0.1076     \n",
      "Epoch 89/300\n",
      "341/341 [==============================] - 0s - loss: 0.1070     \n",
      "Epoch 90/300\n",
      "341/341 [==============================] - 0s - loss: 0.1066     \n",
      "Epoch 91/300\n",
      "341/341 [==============================] - 0s - loss: 0.1063     \n",
      "Epoch 92/300\n",
      "341/341 [==============================] - 0s - loss: 0.1057     \n",
      "Epoch 93/300\n",
      "341/341 [==============================] - 0s - loss: 0.1053     \n",
      "Epoch 94/300\n",
      "341/341 [==============================] - 0s - loss: 0.1047     \n",
      "Epoch 95/300\n",
      "341/341 [==============================] - 0s - loss: 0.1043     \n",
      "Epoch 96/300\n",
      "341/341 [==============================] - 0s - loss: 0.1042     \n",
      "Epoch 97/300\n",
      "341/341 [==============================] - 0s - loss: 0.1039     \n",
      "Epoch 98/300\n",
      "341/341 [==============================] - 0s - loss: 0.1035     \n",
      "Epoch 99/300\n",
      "341/341 [==============================] - 0s - loss: 0.1029     \n",
      "Epoch 100/300\n",
      "341/341 [==============================] - 0s - loss: 0.1024     \n",
      "Epoch 101/300\n",
      "341/341 [==============================] - 0s - loss: 0.1022     \n",
      "Epoch 102/300\n",
      "341/341 [==============================] - 0s - loss: 0.1016     \n",
      "Epoch 103/300\n",
      "341/341 [==============================] - 0s - loss: 0.1016     \n",
      "Epoch 104/300\n",
      "341/341 [==============================] - 0s - loss: 0.1012     \n",
      "Epoch 105/300\n",
      "341/341 [==============================] - 0s - loss: 0.1007     \n",
      "Epoch 106/300\n",
      "341/341 [==============================] - 0s - loss: 0.1005     \n",
      "Epoch 107/300\n",
      "341/341 [==============================] - 0s - loss: 0.0999     \n",
      "Epoch 108/300\n",
      "341/341 [==============================] - 0s - loss: 0.0997     \n",
      "Epoch 109/300\n",
      "341/341 [==============================] - 0s - loss: 0.0994     \n",
      "Epoch 110/300\n",
      "341/341 [==============================] - 0s - loss: 0.0991     \n",
      "Epoch 111/300\n",
      "341/341 [==============================] - 0s - loss: 0.0988     \n",
      "Epoch 112/300\n",
      "341/341 [==============================] - 0s - loss: 0.0986     \n",
      "Epoch 113/300\n",
      "341/341 [==============================] - 0s - loss: 0.0982     \n",
      "Epoch 114/300\n",
      "341/341 [==============================] - 0s - loss: 0.0978     \n",
      "Epoch 115/300\n",
      "341/341 [==============================] - 0s - loss: 0.0973     \n",
      "Epoch 116/300\n",
      "341/341 [==============================] - 0s - loss: 0.0970     \n",
      "Epoch 117/300\n",
      "341/341 [==============================] - 0s - loss: 0.0968     \n",
      "Epoch 118/300\n",
      "341/341 [==============================] - 0s - loss: 0.0966     \n",
      "Epoch 119/300\n",
      "341/341 [==============================] - 0s - loss: 0.0962     \n",
      "Epoch 120/300\n",
      "341/341 [==============================] - 0s - loss: 0.0960     \n",
      "Epoch 121/300\n",
      "341/341 [==============================] - 0s - loss: 0.0956     \n",
      "Epoch 122/300\n",
      "341/341 [==============================] - 0s - loss: 0.0952     \n",
      "Epoch 123/300\n",
      "341/341 [==============================] - 0s - loss: 0.0951     \n",
      "Epoch 124/300\n",
      "341/341 [==============================] - 0s - loss: 0.0948     \n",
      "Epoch 125/300\n",
      "341/341 [==============================] - 0s - loss: 0.0945     \n",
      "Epoch 126/300\n",
      "341/341 [==============================] - 0s - loss: 0.0940     \n",
      "Epoch 127/300\n",
      "341/341 [==============================] - 0s - loss: 0.0939     \n",
      "Epoch 128/300\n",
      "341/341 [==============================] - 0s - loss: 0.0937     \n",
      "Epoch 129/300\n",
      "341/341 [==============================] - 0s - loss: 0.0933     \n",
      "Epoch 130/300\n",
      "341/341 [==============================] - 0s - loss: 0.0929     \n",
      "Epoch 131/300\n",
      "341/341 [==============================] - 0s - loss: 0.0927     \n",
      "Epoch 132/300\n",
      "341/341 [==============================] - 0s - loss: 0.0925     \n",
      "Epoch 133/300\n",
      "341/341 [==============================] - 0s - loss: 0.0921     \n",
      "Epoch 134/300\n",
      "341/341 [==============================] - 0s - loss: 0.0920     \n",
      "Epoch 135/300\n",
      "341/341 [==============================] - 0s - loss: 0.0916     \n",
      "Epoch 136/300\n",
      "341/341 [==============================] - 0s - loss: 0.0916     \n",
      "Epoch 137/300\n",
      "341/341 [==============================] - 0s - loss: 0.0912     \n",
      "Epoch 138/300\n",
      "341/341 [==============================] - 0s - loss: 0.0909     \n",
      "Epoch 139/300\n",
      "341/341 [==============================] - 0s - loss: 0.0905     \n",
      "Epoch 140/300\n",
      "341/341 [==============================] - 0s - loss: 0.0905     \n",
      "Epoch 141/300\n",
      "341/341 [==============================] - 0s - loss: 0.0902     \n",
      "Epoch 142/300\n",
      "341/341 [==============================] - 0s - loss: 0.0901     \n",
      "Epoch 143/300\n",
      "341/341 [==============================] - 0s - loss: 0.0902     \n",
      "Epoch 144/300\n",
      "341/341 [==============================] - 0s - loss: 0.0892     \n",
      "Epoch 145/300\n",
      "341/341 [==============================] - 0s - loss: 0.0889     \n",
      "Epoch 146/300\n",
      "341/341 [==============================] - 0s - loss: 0.0886     \n",
      "Epoch 147/300\n",
      "341/341 [==============================] - 0s - loss: 0.0891     \n",
      "Epoch 148/300\n",
      "341/341 [==============================] - 0s - loss: 0.0883     \n",
      "Epoch 149/300\n",
      "341/341 [==============================] - 0s - loss: 0.0881     \n",
      "Epoch 150/300\n",
      "341/341 [==============================] - 0s - loss: 0.0877     \n",
      "Epoch 151/300\n",
      "341/341 [==============================] - 0s - loss: 0.0879     \n",
      "Epoch 152/300\n",
      "341/341 [==============================] - 0s - loss: 0.0873     \n",
      "Epoch 153/300\n",
      "341/341 [==============================] - 0s - loss: 0.0869     \n",
      "Epoch 154/300\n",
      "341/341 [==============================] - 0s - loss: 0.0869     \n",
      "Epoch 155/300\n",
      "341/341 [==============================] - 0s - loss: 0.0869     \n",
      "Epoch 156/300\n",
      "341/341 [==============================] - 0s - loss: 0.0866     \n",
      "Epoch 157/300\n",
      "341/341 [==============================] - 0s - loss: 0.0863     \n",
      "Epoch 158/300\n",
      "341/341 [==============================] - 0s - loss: 0.0860     \n",
      "Epoch 159/300\n",
      "341/341 [==============================] - 0s - loss: 0.0859     \n",
      "Epoch 160/300\n",
      "341/341 [==============================] - 0s - loss: 0.0852     \n",
      "Epoch 161/300\n",
      "341/341 [==============================] - 0s - loss: 0.0851     \n",
      "Epoch 162/300\n",
      "341/341 [==============================] - 0s - loss: 0.0850     \n",
      "Epoch 163/300\n",
      "341/341 [==============================] - 0s - loss: 0.0848     \n",
      "Epoch 164/300\n",
      "341/341 [==============================] - 0s - loss: 0.0846     \n",
      "Epoch 165/300\n",
      "341/341 [==============================] - 0s - loss: 0.0843     \n",
      "Epoch 166/300\n",
      "341/341 [==============================] - 0s - loss: 0.0840     \n",
      "Epoch 167/300\n",
      "341/341 [==============================] - 0s - loss: 0.0838     \n",
      "Epoch 168/300\n",
      "341/341 [==============================] - 0s - loss: 0.0835     \n",
      "Epoch 169/300\n",
      "341/341 [==============================] - 0s - loss: 0.0837     \n",
      "Epoch 170/300\n",
      "341/341 [==============================] - 0s - loss: 0.0831     \n",
      "Epoch 171/300\n",
      "341/341 [==============================] - 0s - loss: 0.0833     \n",
      "Epoch 172/300\n",
      "341/341 [==============================] - 0s - loss: 0.0828     \n",
      "Epoch 173/300\n",
      "341/341 [==============================] - 0s - loss: 0.0827     \n",
      "Epoch 174/300\n",
      "341/341 [==============================] - 0s - loss: 0.0825     \n",
      "Epoch 175/300\n",
      "341/341 [==============================] - 0s - loss: 0.0823     \n",
      "Epoch 176/300\n",
      "341/341 [==============================] - 0s - loss: 0.0822     \n",
      "Epoch 177/300\n",
      "341/341 [==============================] - 0s - loss: 0.0817     \n",
      "Epoch 178/300\n",
      "341/341 [==============================] - 0s - loss: 0.0818     \n",
      "Epoch 179/300\n",
      "341/341 [==============================] - 0s - loss: 0.0811     \n",
      "Epoch 180/300\n",
      "341/341 [==============================] - 0s - loss: 0.0812     \n",
      "Epoch 181/300\n",
      "341/341 [==============================] - 0s - loss: 0.0811     \n",
      "Epoch 182/300\n",
      "341/341 [==============================] - 0s - loss: 0.0807     \n",
      "Epoch 183/300\n",
      "341/341 [==============================] - 0s - loss: 0.0807     \n",
      "Epoch 184/300\n",
      "341/341 [==============================] - 0s - loss: 0.0802     \n",
      "Epoch 185/300\n",
      "341/341 [==============================] - 0s - loss: 0.0801     \n",
      "Epoch 186/300\n",
      "341/341 [==============================] - 0s - loss: 0.0798     \n",
      "Epoch 187/300\n",
      "341/341 [==============================] - 0s - loss: 0.0796     \n",
      "Epoch 188/300\n",
      "341/341 [==============================] - 0s - loss: 0.0796     \n",
      "Epoch 189/300\n",
      "341/341 [==============================] - 0s - loss: 0.0795     \n",
      "Epoch 190/300\n",
      "341/341 [==============================] - 0s - loss: 0.0792     \n",
      "Epoch 191/300\n",
      "341/341 [==============================] - 0s - loss: 0.0792     \n",
      "Epoch 192/300\n",
      "341/341 [==============================] - 0s - loss: 0.0786     \n",
      "Epoch 193/300\n",
      "341/341 [==============================] - 0s - loss: 0.0785     \n",
      "Epoch 194/300\n",
      "341/341 [==============================] - 0s - loss: 0.0784     \n",
      "Epoch 195/300\n",
      "341/341 [==============================] - 0s - loss: 0.0785     \n",
      "Epoch 196/300\n",
      "341/341 [==============================] - 0s - loss: 0.0779     \n",
      "Epoch 197/300\n",
      "341/341 [==============================] - 0s - loss: 0.0778     \n",
      "Epoch 198/300\n",
      "341/341 [==============================] - 0s - loss: 0.0774     \n",
      "Epoch 199/300\n",
      "341/341 [==============================] - 0s - loss: 0.0776     \n",
      "Epoch 200/300\n",
      "341/341 [==============================] - 0s - loss: 0.0775     \n",
      "Epoch 201/300\n",
      "341/341 [==============================] - 0s - loss: 0.0772     \n",
      "Epoch 202/300\n",
      "341/341 [==============================] - 0s - loss: 0.0772     \n",
      "Epoch 203/300\n",
      "341/341 [==============================] - 0s - loss: 0.0769     \n",
      "Epoch 204/300\n",
      "341/341 [==============================] - 0s - loss: 0.0766     \n",
      "Epoch 205/300\n",
      "341/341 [==============================] - 0s - loss: 0.0762     \n",
      "Epoch 206/300\n",
      "341/341 [==============================] - 0s - loss: 0.0761     \n",
      "Epoch 207/300\n",
      "341/341 [==============================] - 0s - loss: 0.0760     \n",
      "Epoch 208/300\n",
      "341/341 [==============================] - 0s - loss: 0.0760     \n",
      "Epoch 209/300\n",
      "341/341 [==============================] - 0s - loss: 0.0758     \n",
      "Epoch 210/300\n",
      "341/341 [==============================] - 0s - loss: 0.0754     \n",
      "Epoch 211/300\n",
      "341/341 [==============================] - 0s - loss: 0.0754     \n",
      "Epoch 212/300\n",
      "341/341 [==============================] - 0s - loss: 0.0752     \n",
      "Epoch 213/300\n",
      "341/341 [==============================] - 0s - loss: 0.0753     \n",
      "Epoch 214/300\n",
      "341/341 [==============================] - 0s - loss: 0.0749     \n",
      "Epoch 215/300\n",
      "341/341 [==============================] - 0s - loss: 0.0747     \n",
      "Epoch 216/300\n",
      "341/341 [==============================] - 0s - loss: 0.0746     "
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "Xm = X_train_scaled.as_matrix()\n",
    "ym = y_train_scaled.as_matrix()\n",
    "kfold = cross_validation.KFold(len(Xm), 10)\n",
    "cvscores = []\n",
    "for i, (train, val) in enumerate(kfold):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_dim=Xm.shape[1], init='uniform'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1, init='uniform'))\n",
    "    model.add(Activation('linear'))\n",
    "    # Compile model\n",
    "    sgd = SGD(lr=0.2)\n",
    "    model.compile(optimizer='sgd',loss='mean_squared_error')\n",
    "    # Fit the model\n",
    "    model.fit(Xm[train], ym[train], nb_epoch=300)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(Xm[val], ym[val])\n",
    "    cvscores.append(scores)\n",
    "\n",
    "mse_cv = np.mean(cvscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) La función $\\texttt{load_CIFAR10}$ permite generar el training set, testing set y validation set a partir de los datos de CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ejercicio 3\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread\n",
    "# Inicializar semilla aleatoria\n",
    "np.random.seed(20)\n",
    "\n",
    "# Carga de un archivo de CIFAR\n",
    "def load_CIFAR_one(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = pickle.load(f)\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        Y = np.array(Y)\n",
    "        return X, Y\n",
    "\n",
    "# Carga todos los archivos CIFAR y generar Training set, Testing set y Validation set\n",
    "def load_CIFAR10(PATH, n_files=6):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    # Juntar toda la data de entrenamiento\n",
    "    for b in range(1, n_files):\n",
    "        f = os.path.join(PATH, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_one(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    # Obtener subconjunto para validacion a partir de data de entrenamiento\n",
    "    v_size = np.random.randint(1000, 5000)\n",
    "    indices = np.random.choice(np.arange(Xtr.shape[0]), v_size)\n",
    "    mask_tr = np.ones(Xtr.shape[0], dtype=bool)\n",
    "    mask_tr[indices] = False\n",
    "    mask_v = np.invert(mask_tr)\n",
    "    Xv = Xtr[mask_v]\n",
    "    Yv = Ytr[mask_v]\n",
    "    Xtr = Xtr[mask_tr]\n",
    "    Ytr = Ytr[mask_tr]\n",
    "    # Obtener data de prueba\n",
    "    Xte, Yte = load_CIFAR_one(os.path.join(PATH, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte, Xv, Yv\n",
    "\n",
    "# Cargar desde carpeta local data\n",
    "Xtr, Ytr, Xte, Yte, Xv, Yv = load_CIFAR10(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Escalamiento y centrado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Centrar dataset y escalar segun preferencia\n",
    "def preprocess(X, with_mean=True, with_std=True):\n",
    "    scaler = StandardScaler(with_mean, with_std).fit(X)\n",
    "    return scaler.transform(X)\n",
    "\n",
    "# Data solo centrada\n",
    "#Xtr_c = preprocess(Xtr, with_mean=True, with_std=False)\n",
    "# Data solo escalada\n",
    "#Xtr_s = preprocess(Xtr, with_mean=False, with_std=True)\n",
    "# Data centrada y escalada\n",
    "Xtr_cs = preprocess(Xtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "c) Creación de red neuronal para problema CIFAR. Se experimentó con diversas arquitecturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error when checking model target: expected activation_52 to have shape (None, 2) but got array with shape (45793, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-d7cfeef687de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mMLPmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;31m#MLPmodel.fit(Xtr_cs, Ytr, nb_epoch=20, batch_size=16)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#score = MLPmodel.evaluate(Xte, Yte, batch_size=16)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                                                            \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m                                                            \u001b[0mcheck_batch_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m                                                            batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1033\u001b[0m         \u001b[1;31m# prepare validation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[0;32m    961\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                                    exception_prefix='model target')\n\u001b[0m\u001b[0;32m    964\u001b[0m         sample_weights = standardize_sample_weights(sample_weight,\n\u001b[0;32m    965\u001b[0m                                                     self.output_names)\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[0;32m    106\u001b[0m                                         \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m                                         \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                                         str(array.shape))\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Error when checking model target: expected activation_52 to have shape (None, 2) but got array with shape (45793, 1)"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "# Modelo 1: Multilayer Perceptron\n",
    "input_dim = Xtr.shape[1]\n",
    "MLPmodel = Sequential()\n",
    "MLPmodel.add(Dense(32, input_dim=input_dim, init='uniform'))\n",
    "MLPmodel.add(Activation('relu'))\n",
    "MLPmodel.add(Dense(2, init='uniform'))\n",
    "MLPmodel.add(Activation('softmax'))\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "MLPmodel.compile(loss='mean_squared_error',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "MLPmodel.fit(Xtr,Ytr)\n",
    "#MLPmodel.fit(Xtr_cs, Ytr, nb_epoch=20, batch_size=16)\n",
    "#score = MLPmodel.evaluate(Xte, Yte, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
