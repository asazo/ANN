{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 2: Análisis de sentimientos usando RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from matplotlib import pyplot\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Cargar el dataset completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "np.random.seed(3)\n",
    "srng = RandomStreams(8)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(seed=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Cantidad de palabras en el dataset, boxplot de distribución de largo de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el dataset:  50000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFkCAYAAACjCwibAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ddca30190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenamiento de conjuntos de entrenamiento\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "print \"Palabras en el dataset: \", X.size\n",
    "result = map(len, X)\n",
    "pyplot.boxplot(result)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Cargar palabras más relevantes y acotar largo de comentarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se cargan las 3000 palabras más relevantes\n",
    "top_words = 3000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words, seed=15)\n",
    "\n",
    "# Se acotan los comentarios a un máximo de 500 palabras\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Entrenamiento red LSTM con capa de embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 500, 32)       96000       embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 100)           53200       embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             101         lstm_1[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 149301\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Tamaño vector generado por embedding\n",
    "embedding_vector_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vector_length, input_length=500))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Se entrena el modelo en servidor GPU y se guarda para luego ser evaluado\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=64)\n",
    "model.save('Pregunta2/LSTM-32.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 0.86072000000000004)\n"
     ]
    }
   ],
   "source": [
    "model = load_model('Pregunta2/LSTM-32.h5')\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy: ', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Entrenamiento red LSTM con distintos tamaños de vector de embedding, se prueba con valores 16 y 64 además del 32 de la pregunta anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, 500, 16)       48000       embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 100)           46800       embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             101         lstm_2[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 94901\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Tamaño vector generado por embedding largo 16\n",
    "embedding_vector_length = 16\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vector_length, input_length=500))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Se entrena el modelo en servidor GPU y se guarda para luego ser evaluado\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=64)\n",
    "model.save('pregunta2/LSTM-16.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_3 (Embedding)          (None, 500, 64)       192000      embedding_input_4[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 100)           66000       embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             101         lstm_3[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 258101\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Tamaño vector generado por embedding largo 64\n",
    "embedding_vector_length = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vector_length, input_length=500))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Se entrena el modelo en servidor GPU y se guarda para luego ser evaluado\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=64)\n",
    "model.save('pregunta2/LSTM-64.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy tama\\xc3\\xb1o de vector 16: ', 0.84792000000000001)\n",
      "('Accuracy tama\\xc3\\xb1o de vector 32: ', 0.86072000000000004)\n",
      "('Accuracy tama\\xc3\\xb1o de vector 64: ', 0.86680000000000001)\n",
      "('P\\xc3\\xa9rdida tama\\xc3\\xb1o de vector 16: ', 0.35966520366907118)\n",
      "('P\\xc3\\xa9rdida tama\\xc3\\xb1o de vector 32: ', 0.33023624739646912)\n",
      "('P\\xc3\\xa9rdida tama\\xc3\\xb1o de vector 64: ', 0.32640593312382699)\n"
     ]
    }
   ],
   "source": [
    "# Se cargan los modelos obtenidos\n",
    "model16 = load_model('Pregunta2/LSTM-16.h5')\n",
    "model32 = load_model('Pregunta2/LSTM-32.h5')\n",
    "model64 = load_model('Pregunta2/LSTM-64.h5')\n",
    "\n",
    "# Se obtiene el accuracy de cada modelo\n",
    "scores16 = model16.evaluate(X_test, y_test, verbose=0)\n",
    "scores32 = model32.evaluate(X_test, y_test, verbose=0)\n",
    "scores64 = model64.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Accuracy tamaño de vector 16: ', scores16[1])\n",
    "print('Accuracy tamaño de vector 32: ', scores32[1])\n",
    "print('Accuracy tamaño de vector 64: ', scores64[1])\n",
    "\n",
    "print('Pérdida tamaño de vector 16: ', scores16[0])\n",
    "print('Pérdida tamaño de vector 32: ', scores32[0])\n",
    "print('Pérdida tamaño de vector 64: ', scores64[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Entrenamiento cambiando el tamaño de las palabras seleccionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se probará con 3000, 5000 y 8000 palabras top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_4 (Embedding)          (None, 500, 32)       96000       embedding_input_8[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (None, 100)           53200       embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             101         lstm_4[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 149301\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Se cargan las 3000 palabras más relevantes\n",
    "top_words = 3000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words, seed=15)\n",
    "\n",
    "# Se acotan los comentarios a un máximo de 500 palabras\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "\n",
    "# Tamaño vector generado por embedding largo 32\n",
    "embedding_vector_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vector_length, input_length=500))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Se entrena el modelo en servidor GPU y se guarda para luego ser evaluado\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=64)\n",
    "model.save('pregunta2/LSTM-words-3000.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_5 (Embedding)          (None, 500, 32)       160000      embedding_input_9[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                    (None, 100)           53200       embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 1)             101         lstm_5[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 213301\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Se cargan las 5000 palabras más relevantes\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words, seed=15)\n",
    "\n",
    "# Se acotan los comentarios a un máximo de 500 palabras\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "\n",
    "# Tamaño vector generado por embedding largo 32\n",
    "embedding_vector_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vector_length, input_length=500))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Se entrena el modelo en servidor GPU y se guarda para luego ser evaluado\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=64)\n",
    "model.save('pregunta2/LSTM-words-5000.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_6 (Embedding)          (None, 500, 32)       256000      embedding_input_10[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                    (None, 100)           53200       embedding_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1)             101         lstm_6[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 309301\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Se cargan las 8000 palabras más relevantes\n",
    "top_words = 8000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words, seed=15)\n",
    "\n",
    "# Se acotan los comentarios a un máximo de 500 palabras\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "\n",
    "# Tamaño vector generado por embedding largo 32\n",
    "embedding_vector_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vector_length, input_length=500))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# Se entrena el modelo en servidor GPU y se guarda para luego ser evaluado\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=64)\n",
    "model.save('pregunta2/LSTM-words-8000.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy cantidad de palabras 3000: ', 0.86199999999999999)\n",
      "('Accuracy cantidad de palabras 5000: ', 0.87231999999999998)\n",
      "('Accuracy cantidad de palabras 8000: ', 0.86387999999999998)\n",
      "('Perdida cantidad de palabras 3000: ', 0.32267902331829074)\n",
      "('Perdida cantidad de palabras 5000: ', 0.30801745999336244)\n",
      "('Perdida cantidad de palabras 8000: ', 0.31699821529388428)\n"
     ]
    }
   ],
   "source": [
    "# Se cargan los modelos opbtenidos\n",
    "model_3000 = load_model('Pregunta2/LSTM-words-3000.h5')\n",
    "model_5000 = load_model('Pregunta2/LSTM-words-5000.h5')\n",
    "model_8000 = load_model('Pregunta2/LSTM-words-8000.h5')\n",
    "\n",
    "# Se obtiene el accuracy de cada modelo\n",
    "\n",
    "# Se cargan las 8000 palabras más relevantes\n",
    "top_words = 3000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words, seed=15)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "scores3000 = model_3000.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words, seed=15)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "scores5000 = model_5000.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "top_words = 8000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words, seed=15)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "scores8000 = model_8000.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Accuracy cantidad de palabras 3000: ', scores3000[1])\n",
    "print('Accuracy cantidad de palabras 5000: ', scores5000[1])\n",
    "print('Accuracy cantidad de palabras 8000: ', scores8000[1])\n",
    "\n",
    "print('Perdida cantidad de palabras 3000: ', scores3000[0])\n",
    "print('Perdida cantidad de palabras 5000: ', scores5000[0])\n",
    "print('Perdida cantidad de palabras 8000: ', scores8000[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Usar Dropout para entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_7 (Embedding)          (None, 500, 32)       160000      embedding_input_17[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 500, 32)       0           embedding_7[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                    (None, 100)           53200       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 100)           0           lstm_7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 1)             101         dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 213301\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_length = 32\n",
    "top_words = 5000\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vector_length, input_length=500))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model.fit(X_train, y_train, nb_epoch=3, batch_size=64)\n",
    "model.save('pregunta2/LSTM-dropout.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 0.86987999999999999)\n",
      "('P\\xc3\\xa9rdida: ', 0.31332884783506393)\n"
     ]
    }
   ],
   "source": [
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words, seed=15)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "\n",
    "model = load_model('Pregunta2/LSTM-dropout.h5')\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Accuracy: ', scores[1])\n",
    "print('Pérdida: ', scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Propuesta nuevo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 500, 64)       320000      embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 500, 64)       0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 100)           66000       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 100)           0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             101         dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 386101\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words, seed=15)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "embedding_vector_length = 64\n",
    "top_words = 5000\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vector_length, input_length=500))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model.fit(X_train, y_train, nb_epoch=3, batch_size=64)\n",
    "model.save('pregunta2/LSTM-dropout-64.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 0.85399999999999998)\n",
      "('P\\xc3\\xa9rdida: ', 0.35145377113342285)\n"
     ]
    }
   ],
   "source": [
    "model = load_model('Pregunta2/LSTM-dropout-64.h5')\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Accuracy: ', scores[1])\n",
    "print('Pérdida: ', scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, 500, 64)       320000      embedding_input_4[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 500, 64)       0           embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 100)           66000       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 100)           0           lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             101         dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 386101\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words, seed=15)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "embedding_vector_length = 64\n",
    "top_words = 5000\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vector_length, input_length=500))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model.fit(X_train, y_train, nb_epoch=3, batch_size=64)\n",
    "model.save('pregunta2/LSTM-dropout-64.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 0.86287999999999998)\n",
      "('Perdida: ', 0.32029778882503507)\n"
     ]
    }
   ],
   "source": [
    "model = load_model('Pregunta2/LSTM-dropout-64-2.h5')\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Accuracy: ', scores[1])\n",
    "print('Perdida: ', scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 500, 32)       160000      embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 500, 32)       0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 100)           53200       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 100)           0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             101         dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 213301\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words, seed=15)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "embedding_vector_length = 32\n",
    "top_words = 5000\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vector_length, input_length=500))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model.fit(X_train, y_train, nb_epoch=3, batch_size=64)\n",
    "model.save('pregunta2/LSTM-dropout-64-3.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 0.87439999999999996)\n",
      "('Perdida: ', 0.32589475166678428)\n"
     ]
    }
   ],
   "source": [
    "model = load_model('Pregunta2/LSTM-dropout-64-3.h5')\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Accuracy: ', scores[1])\n",
    "print('Perdida: ', scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
